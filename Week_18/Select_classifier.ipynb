{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cef9ef3c-9a4c-4d5f-9439-82b610d13e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Classifier  Accuracy  Precision    Recall  F1 Score\n",
      "1           Random Forest     0.900   0.939394  0.869159  0.902913\n",
      "3           Decision Tree     0.865   0.908163  0.831776  0.868293\n",
      "0     Logistic Regression     0.855   0.914894  0.803738  0.855721\n",
      "2  Support Vector Machine     0.845   0.895833  0.803738  0.847291\n",
      "4     K-Nearest Neighbors     0.810   0.879121  0.747664  0.808081\n",
      "\n",
      "Logistic Regression Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.91      0.85        93\n",
      "           1       0.91      0.80      0.86       107\n",
      "\n",
      "    accuracy                           0.85       200\n",
      "   macro avg       0.86      0.86      0.85       200\n",
      "weighted avg       0.86      0.85      0.86       200\n",
      "\n",
      "\n",
      "Random Forest Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.94      0.90        93\n",
      "           1       0.94      0.87      0.90       107\n",
      "\n",
      "    accuracy                           0.90       200\n",
      "   macro avg       0.90      0.90      0.90       200\n",
      "weighted avg       0.90      0.90      0.90       200\n",
      "\n",
      "\n",
      "Support Vector Machine Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84        93\n",
      "           1       0.90      0.80      0.85       107\n",
      "\n",
      "    accuracy                           0.84       200\n",
      "   macro avg       0.85      0.85      0.84       200\n",
      "weighted avg       0.85      0.84      0.85       200\n",
      "\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        93\n",
      "           1       0.91      0.83      0.87       107\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.87      0.87      0.86       200\n",
      "weighted avg       0.87      0.86      0.87       200\n",
      "\n",
      "\n",
      "K-Nearest Neighbors Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81        93\n",
      "           1       0.88      0.75      0.81       107\n",
      "\n",
      "    accuracy                           0.81       200\n",
      "   macro avg       0.82      0.81      0.81       200\n",
      "weighted avg       0.82      0.81      0.81       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Dummy dataset\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define classifiers\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC(probability=True),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "}\n",
    "\n",
    "# Initialize a DataFrame to store results\n",
    "results = pd.DataFrame(columns=[\"Classifier\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"ROC-AUC\"])\n",
    "\n",
    "# Loop through classifiers and evaluate\n",
    "# Initialize a list to collect results\n",
    "results_list = []\n",
    "\n",
    "# Loop through classifiers and evaluate\n",
    "for name, clf in classifiers.items():\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    # y_proba = clf.predict_proba(X_test)[:, 1] if hasattr(clf, \"predict_proba\") else None\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    # roc_auc = roc_auc_score(y_test, y_proba) if y_proba is not None else np.nan\n",
    "    \n",
    "    # Collect results as a dictionary\n",
    "    results_list.append({\n",
    "        \"Classifier\": name,\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"F1 Score\": f1,\n",
    "        # \"ROC-AUC\": roc_auc,\n",
    "    })\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "results = pd.DataFrame(results_list)\n",
    "\n",
    "# Display results\n",
    "print(results.sort_values(by=\"Accuracy\", ascending=False))\n",
    "\n",
    "# Optional: Detailed classification report for each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(f\"\\n{name} Classification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737b0583-d672-4089-925f-d043f6be1e9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
