{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8910d2a-acf3-485e-be5e-a42b13046f3c",
   "metadata": {},
   "source": [
    "# Evaluation metrics used for regression problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c6629-cb9e-4135-95da-7c83912566c4",
   "metadata": {},
   "source": [
    "Mean Squared Error (MSE)\n",
    "- Calculates the average of squared differences between predictions and actual values\n",
    "- Heavily penalizes large errors due to squaring\n",
    "- Formula: MSE = (1/n) * Σ(y_true - y_pred)²\n",
    "- Always non-negative, with 0 indicating perfect predictions\n",
    "- Useful when large errors are particularly undesirable\n",
    "\n",
    "Root Mean Squared Error (RMSE)\n",
    "- Square root of MSE\n",
    "- Expressed in same units as the target variable, making it more interpretable\n",
    "- Formula: RMSE = √(MSE)\n",
    "- Popular metric for many regression problems\n",
    "- Good default choice when you want error in original units\n",
    "\n",
    "Mean Absolute Error (MAE)\n",
    "- Average of absolute differences between predictions and actual values\n",
    "- Formula: MAE = (1/n) * Σ|y_true - y_pred|\n",
    "- More robust to outliers than MSE/RMSE\n",
    "- Useful when outliers should not heavily influence the error metric\n",
    "\n",
    "R-squared (R²) / Coefficient of Determination\n",
    "- Represents proportion of variance in dependent variable explained by independent variables\n",
    "- Ranges from 0 to 1 (or negative in case of poor fit)\n",
    "- Formula: R² = 1 - (Sum of squared residuals)/(Total sum of squares)\n",
    "- Useful for explaining model performance to non-technical stakeholders\n",
    "- Be cautious: high R² doesn't always mean good predictions\n",
    "\n",
    "Adjusted R-squared\n",
    "- Modified version of R² that accounts for number of predictors\n",
    "- Penalizes adding unnecessary features\n",
    "- Formula: Adjusted R² = 1 - [(1-R²)(n-1)/(n-k-1)]\n",
    "  * R² = The regular R-squared value (coefficient of determination)\n",
    "  * n = The total number of data points (sample size)\n",
    "  * k = The number of independent variables (predictors/features) in the model \n",
    "- Better than R² when comparing models with different numbers of features\n",
    "- Helps prevent overfitting\n",
    "\n",
    "Mean Absolute Percentage Error (MAPE)\n",
    "- Average of percentage differences between predictions and actual values\n",
    "- Formula: MAPE = (100/n) * Σ|((y_true - y_pred)/y_true)|\n",
    "- Good for comparing errors across different scales\n",
    "- Cannot be used when actual values include zeros\n",
    "- Useful in forecasting and business contexts\n",
    "\n",
    "When choosing metrics:\n",
    "1. Consider your problem's requirements (e.g., sensitivity to outliers)\n",
    "2. Think about interpretability needs\n",
    "3. Account for your data's characteristics\n",
    "4. Use multiple metrics for a comprehensive evaluation\n",
    "\n",
    "\n",
    "\n",
    "### **Which Metric to Use?**\n",
    "| Metric | When to Use? |\n",
    "|--------|-------------|\n",
    "| **MAE** | If you want a simple interpretation and equal weight for all errors. |\n",
    "| **MSE** | If you want to penalize larger errors more than smaller ones. |\n",
    "| **RMSE** | If you want an error metric in the same unit as the target variable. |\n",
    "| **MAPE** | If you need a percentage error but avoid it with zero values. |\n",
    "| **R² Score** | To measure how well the model explains variance. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b77d72a-27e7-4e58-b97e-0477c3f4c1e8",
   "metadata": {},
   "source": [
    "# Evaluation methods for clustering. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831882bc-18e3-440b-ba07-a8251d13189d",
   "metadata": {},
   "source": [
    "Internal Evaluation Methods (No ground truth needed):\n",
    "\n",
    "1. Silhouette Coefficient\n",
    "- Measures how similar an object is to its own cluster compared to other clusters\n",
    "- Range: -1 to 1 (higher is better)\n",
    "- Good for determining optimal number of clusters\n",
    "- Combines both cohesion and separation measures\n",
    "\n",
    "2. Davies-Bouldin Index\n",
    "- Ratio of within-cluster distances to between-cluster distances\n",
    "- Lower values indicate better clustering\n",
    "- Sensitive to spherical clusters\n",
    "- Good for checking cluster separation\n",
    "\n",
    "3. Calinski-Harabasz Index\n",
    "- Ratio of between-cluster variance to within-cluster variance\n",
    "- Higher values indicate better defined clusters\n",
    "- Also known as Variance Ratio Criterion\n",
    "- Works well for convex clusters\n",
    "\n",
    "4. Dunn Index\n",
    "- Ratio of smallest distance between observations in different clusters to largest intra-cluster distance\n",
    "- Higher values indicate better clustering\n",
    "- Sensitive to noise\n",
    "- Computationally expensive for large datasets\n",
    "\n",
    "External Evaluation Methods (Requires ground truth labels):\n",
    "\n",
    "1. Adjusted Rand Index (ARI)\n",
    "- Measures similarity between two clusterings\n",
    "- Range: -1 to 1 (higher is better)\n",
    "- Adjusted for chance\n",
    "- Popular for comparing with ground truth\n",
    "\n",
    "2. Normalized Mutual Information (NMI)\n",
    "- Measures mutual dependence between two clusterings\n",
    "- Range: 0 to 1 (higher is better)\n",
    "- Normalized for easier interpretation\n",
    "- Less sensitive to number of clusters\n",
    "\n",
    "3. Homogeneity, Completeness, and V-measure\n",
    "- Homogeneity: each cluster contains only members of a single class\n",
    "- Completeness: all members of a given class are in the same cluster\n",
    "- V-measure: harmonic mean of homogeneity and completeness\n",
    "\n",
    "4. Fowlkes-Mallows Score\n",
    "- Geometric mean of precision and recall\n",
    "- Range: 0 to 1 (higher is better)\n",
    "- Good for imbalanced clusters\n",
    "\n",
    "Practical Tips:\n",
    "1. Use multiple metrics for robust evaluation\n",
    "2. Consider your data characteristics when choosing metrics\n",
    "3. For internal validation, prefer metrics that don't assume specific cluster shapes if your data might have irregular clusters\n",
    "4. Watch for metrics that may be biased by number of clusters or dataset size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f135ecd9-90fc-49a1-bcc9-175972891a7a",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "The Silhouette Coefficient is generally considered the most widely used clustering evaluation method, particularly when you don't have ground truth labels (which is common in real-world clustering problems). Here's why it's so popular:\n",
    "\n",
    "Key Advantages:\n",
    "- Works without ground truth labels (internal metric)\n",
    "- Provides an easy-to-understand score between -1 and 1\n",
    "- Combines both cohesion and separation measures\n",
    "- Can be used to determine optimal number of clusters\n",
    "- Works with any distance metric\n",
    "- Available in popular ML libraries like scikit-learn\n",
    "\n",
    "How it works:\n",
    "1. For each point i, calculate:\n",
    "   - a(i): Average distance to all other points in its cluster (cohesion)\n",
    "   - b(i): Average distance to all points in nearest neighbor cluster (separation)\n",
    "\n",
    "2. The Silhouette score for point i is:\n",
    "   s(i) = (b(i) - a(i)) / max(a(i), b(i))\n",
    "\n",
    "3. The overall Silhouette score is the mean of all s(i)\n",
    "\n",
    "Interpretation:\n",
    "- Score near 1: Well-clustered points\n",
    "- Score near 0: Points on cluster boundaries\n",
    "- Score near -1: Points likely assigned to wrong cluster\n",
    "\n",
    "However, it's considered best practice to use multiple evaluation metrics rather than relying solely on Silhouette score, often combining it with:\n",
    "- Davies-Bouldin Index\n",
    "- Calinski-Harabasz Index\n",
    "- If you have ground truth labels: Adjusted Rand Index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ad35f2-c5f3-4e63-ab96-9f54b4c72ce4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
