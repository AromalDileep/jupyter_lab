{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a106b9a-7a44-467b-80e2-781f447e3d6b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Comparing two vecotrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc477d5f-2b23-4d1a-9ad7-78eda559f31b",
   "metadata": {},
   "source": [
    "##  Compare Magnitude (Length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4a81ee-f796-49bb-8f63-c0a6004db8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62763134-589c-4fd0-9218-917606c30310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector 2 is longer.\n"
     ]
    }
   ],
   "source": [
    "def vector_magnitude(v):\n",
    "    return math.sqrt(sum(component**2 for component in v))\n",
    "\n",
    "\n",
    "v1 = (3, 4)   # Vector 1\n",
    "v2 = (5, 12)  # Vector 2\n",
    "\n",
    "magnitude_v1 = vector_magnitude(v1)\n",
    "magnitude_v2 = vector_magnitude(v2)\n",
    "\n",
    "if magnitude_v1 > magnitude_v2:\n",
    "    print(\"Vector 1 is longer.\")\n",
    "elif magnitude_v1 < magnitude_v2:\n",
    "    print(\"Vector 2 is longer.\")\n",
    "else:\n",
    "    print(\"Both vectors have the same length.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f65d557-b5d5-415b-bf70-6b251c900774",
   "metadata": {},
   "source": [
    "##  Compare Direction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff87a2c-053f-42d6-9f29-1afd81384b88",
   "metadata": {},
   "source": [
    "Two vectors are considered to have the same direction if they are parallel. This happens if one is a scalar multiple of the other:\n",
    "\n",
    "\n",
    " \n",
    "Where k is a scalar.\n",
    "\n",
    "If the vectors are in opposite directions, k will be negative.\n",
    "To check if two vectors are parallel, calculate their unit vectors and compare:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72b7d0fb-83c2-490f-9430-7a02279ca9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vectors are parallel.\n"
     ]
    }
   ],
   "source": [
    "def are_parallel(v1, v2):\n",
    "    # Two vectors v1 = (a1, b1) and v2 = (a2, b2) are parallel if:\n",
    "    # a1/a2 = b1/b2 = k (where k is some constant)\n",
    "    # In other words, one vector is a scalar multiple of the other: v1 = k * v2\n",
    "    \n",
    "    # For 2D vectors: (x1,y1) and (x2,y2) are parallel if x1/x2 = y1/y2\n",
    "    # For 3D vectors: (x1,y1,z1) and (x2,y2,z2) are parallel if x1/x2 = y1/y2 = z1/z2\n",
    "    \n",
    "    ratio = [v1[i] / v2[i] if v2[i] != 0 else None for i in range(len(v1))]\n",
    "    return all(r == ratio[0] for r in ratio if r is not None)\n",
    "\n",
    "v1 = (2, 4)\n",
    "v2 = (1, 2)\n",
    "if are_parallel(v1, v2):\n",
    "    print(\"The vectors are parallel.\")\n",
    "else:\n",
    "    print(\"The vectors are not parallel.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aa7509-a95a-418f-af18-469993d42e03",
   "metadata": {},
   "source": [
    "##  Compare Component-wise Equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7004f047-6c54-4a65-b6c7-8ca6c5654d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vectors are equal.\n"
     ]
    }
   ],
   "source": [
    "def are_equal(v1, v2):\n",
    "    return v1 == v2\n",
    "\n",
    "v1 = (3, 4, 5)\n",
    "v2 = (3, 4, 5)\n",
    "\n",
    "if are_equal(v1, v2):\n",
    "    print(\"The vectors are equal.\")\n",
    "else:\n",
    "    print(\"The vectors are not equal.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd153fbc-68d0-4a2e-b738-d18dc1130f41",
   "metadata": {},
   "source": [
    "##  Angle Between Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def35bd5-d8b8-4d42-b705-a1e9562fd910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The angle between the vectors is 90.0 degrees.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def angle_between_vectors(v1, v2):\n",
    "    dot_product = sum(v1[i] * v2[i] for i in range(len(v1)))\n",
    "    # dot_product = np.dot(v1, v2)\n",
    "    magnitude_v1 = vector_magnitude(v1)\n",
    "    magnitude_v2 = vector_magnitude(v2)\n",
    "    cos_theta = dot_product / (magnitude_v1 * magnitude_v2)\n",
    "    return math.degrees(math.acos(cos_theta))\n",
    "\n",
    "v1 = (1, 0)\n",
    "v2 = (0, 1)\n",
    "\n",
    "angle = angle_between_vectors(v1, v2)\n",
    "print(f\"The angle between the vectors is {angle} degrees.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d832d9d0-6bdf-4e65-af1b-b81421edb366",
   "metadata": {},
   "source": [
    "## Python Code for Dot Product Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a3b6a21-62a8-4cfa-8d7f-e078eac126e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vectors point in the same general direction.\n",
      "The vectors point in opposite directions.\n",
      "The vectors are perpendicular.\n"
     ]
    }
   ],
   "source": [
    "def dot_product(v1, v2):\n",
    "    \"\"\"\n",
    "    Calculate the dot product of two vectors.\n",
    "    \"\"\"\n",
    "    return sum(v1[i] * v2[i] for i in range(len(v1)))\n",
    "\n",
    "def compare_vectors(v1, v2):\n",
    "    \"\"\"\n",
    "    Compare two vectors based on their dot product.\n",
    "    \"\"\"\n",
    "    dp = dot_product(v1, v2)\n",
    "    \n",
    "    if dp == 0:\n",
    "        return \"The vectors are perpendicular.\"\n",
    "    elif dp > 0:\n",
    "        return \"The vectors point in the same general direction.\"\n",
    "    else:\n",
    "        return \"The vectors point in opposite directions.\"\n",
    "\n",
    "# Example Usage\n",
    "v1 = (3, 4, 0)  # Vector 1\n",
    "v2 = (6, 8, 0)  # Vector 2 (same direction as v1)\n",
    "v3 = (-3, -4, 0)  # Vector 3 (opposite direction of v1)\n",
    "v4 = (0, 0, 1)  # Vector 4 (perpendicular to v1)\n",
    "\n",
    "print(compare_vectors(v1, v2))  # Output: Same direction\n",
    "print(compare_vectors(v1, v3))  # Output: Opposite direction\n",
    "print(compare_vectors(v1, v4))  # Output: Perpendicular\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2a9268-33e5-40fa-be47-a9f267e813fe",
   "metadata": {},
   "source": [
    "# Eigen value, Eigen vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69274527-f7b3-4757-bb11-823cf7f3223b",
   "metadata": {},
   "source": [
    "##  What Are Eigenvalues and Eigenvectors \n",
    "When a matrix is multiplied by a vector, the result is usually a new vector pointing in a different direction. However, for some special vectors, the direction remains unchanged. These special vectors are called eigenvectors, and the factor by which their magnitude is scaled during this transformation is called the eigenvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1ee05c-9211-4f4a-9215-6d14328915ba",
   "metadata": {},
   "source": [
    "* v: The eigenvector (a non-zero vector).\n",
    "* Î»: The eigenvalue (a scalar).\n",
    "* A: The transformation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf52591e-9658-4939-b81a-b857da497b39",
   "metadata": {},
   "source": [
    "##  Key Intuition\n",
    "Eigenvector: A vector that doesnâ€™t change direction under the linear transformation \n",
    "ð´\n",
    "A. It can get stretched, compressed, or flipped, but the \"line of action\" stays the same.\n",
    "Eigenvalue: The amount by which the eigenvector is scaled.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30af1350-c5e3-472f-a38d-7669fd4f6336",
   "metadata": {},
   "source": [
    "#  Transformations \n",
    "\n",
    "Types of Transformations:\n",
    "\n",
    "1. Linear Transformations\n",
    "- Definition: Maps vectors while preserving vector addition and scalar multiplication\n",
    "- Key characteristics:\n",
    "  * Preserve origin\n",
    "  * Maintain linear relationships\n",
    "  * Can be represented by matrices\n",
    "\n",
    "2. Affine Transformations\n",
    "- Extends linear transformations\n",
    "- Includes translation, rotation, scaling, and shearing\n",
    "- Can move points that don't pass through origin\n",
    "\n",
    "3. Key Transformations in Machine Learning:\n",
    "\n",
    "a) Rotation\n",
    "- Rotates vectors around origin\n",
    "- Uses rotation matrices\n",
    "- Applications:\n",
    "  * Data augmentation\n",
    "  * Feature space manipulation\n",
    "  * Image processing\n",
    "\n",
    "b) Scaling\n",
    "- Changes vector magnitude\n",
    "- Stretches or compresses coordinate spaces\n",
    "- Critical for:\n",
    "  * Feature normalization\n",
    "  * Standardizing input data\n",
    "  * Gradient descent optimization\n",
    "\n",
    "c) Translation\n",
    "- Shifts entire coordinate system\n",
    "- Moves data points\n",
    "- Used in:\n",
    "  * Data preprocessing\n",
    "  * Centering datasets\n",
    "  * Alignment techniques\n",
    "\n",
    "d) Shearing\n",
    "- Skews coordinate axes\n",
    "- Transforms shapes without changing volume\n",
    "- Applications in:\n",
    "  * Image transformations\n",
    "  * Data augmentation\n",
    "  * Geometric understanding\n",
    "\n",
    "4. Specialized Transformations:\n",
    "\n",
    "a) Householder Transformation\n",
    "- Reflects vectors across hyperplanes\n",
    "- Used in:\n",
    "  * QR decomposition\n",
    "  * Eigenvalue computations\n",
    "  * Numerical stability\n",
    "\n",
    "b) Givens Rotation\n",
    "- Rotates 2D coordinate planes\n",
    "- Applications:\n",
    "  * Matrix factorization\n",
    "  * Numerical linear algebra\n",
    "  * Machine learning optimizations\n",
    "\n",
    "5. Important Transformations in Machine Learning:\n",
    "\n",
    "a) Principal Component Analysis (PCA)\n",
    "- Rotates and projects data to maximize variance\n",
    "- Reduces dimensionality\n",
    "- Removes correlations\n",
    "\n",
    "b) Kernel Transformations\n",
    "- Maps data to higher-dimensional spaces\n",
    "- Enables non-linear separability\n",
    "- Used in:\n",
    "  * Support Vector Machines\n",
    "  * Clustering algorithms\n",
    "\n",
    "c) Fourier Transformation\n",
    "- Converts signals between time and frequency domains\n",
    "- Used in:\n",
    "  * Signal processing\n",
    "  * Feature extraction\n",
    "  * Deep learning architectures\n",
    "\n",
    "d) Whitening Transformation\n",
    "- Decorrelates and scales data\n",
    "- Normalizes feature distributions\n",
    "- Improves neural network training\n",
    "\n",
    "6. Geometric Transformations\n",
    "\n",
    "a) Projective Transformations\n",
    "- Maps lines to lines\n",
    "- Preserves collinearity\n",
    "- Used in:\n",
    "  * Computer vision\n",
    "  * Image processing\n",
    "  * Geometric deep learning\n",
    "\n",
    "b) Conformal Transformations\n",
    "- Preserves angles\n",
    "- Maintains local shape\n",
    "- Applications in:\n",
    "  * Geometric deep learning\n",
    "  * Shape analysis\n",
    "\n",
    "Importance in Machine Learning:\n",
    "- Data preprocessing\n",
    "- Feature engineering\n",
    "- Dimensionality reduction\n",
    "- Numerical stability\n",
    "- Computational efficiency\n",
    "- Improved model performance\n",
    "\n",
    "Practical Considerations:\n",
    "- Choose transformations based on:\n",
    "  * Data characteristics\n",
    "  * Problem domain\n",
    "  * Computational constraints\n",
    "  * Desired invariance properties\n",
    "\n",
    "Would you like me to elaborate on any specific transformation or provide practical examples?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88a4e9c-7e3f-4ebc-abec-7d5f0c65d363",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Inverse Matrix\n",
    "\n",
    "The inverse of a matrix is a matrix that, when multiplied with the original matrix, results in the identity matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f278d453-7925-4d56-a043-19f8796d404e",
   "metadata": {},
   "source": [
    "# Transpose\n",
    "\n",
    "The transpose of a matrix is an operation that flips a matrix over its diagonal, turning its rows into columns and its columns into rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ad62b-6f93-42d6-b3e8-afa58578828e",
   "metadata": {},
   "source": [
    "# (PDF)\n",
    " A **probability density function (PDF)** describes the likelihood of a continuous random variable taking on specific values. It represents the relative likelihood of the variable near a given value and integrates to 1 over the entire range of possible values. For example, the PDF of a normal distribution is a bell-shaped curve showing probabilities distributed around the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "948edce5-c20e-47c1-ae99-8f8506c298f3",
   "metadata": {},
   "source": [
    "# (PMF)\n",
    "A **probability mass function (PMF)** describes the probability of a discrete random variable taking on specific values. It assigns probabilities to individual outcomes, ensuring the total probability over all possible outcomes equals 1. For example, for a fair six-sided die, the PMF assigns a probability of \\( \\frac{1}{6} \\) to each outcome (1, 2, 3, 4, 5, 6)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240b1430-5800-4421-b170-96df38612813",
   "metadata": {},
   "source": [
    "# Random vairable\n",
    "A random variable is a variable whose values are determined by the outcome of a random process or experiment. Let me explain its key concepts:\n",
    "\n",
    "Definition:\n",
    "\n",
    "\n",
    "* A function that assigns a numerical value to each outcome in a sample space\n",
    "* Can be discrete (countable values) or continuous (uncountable values)\n",
    "\n",
    "Types of Random Variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1eca79-82dc-4bb5-aa72-ad11d1a516ec",
   "metadata": {},
   "source": [
    "*  Discrete Random Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "edc90b4c-63b0-4fb4-b9ee-1aa242bd021d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of heads in 3 coin flips: {0, 1, 2, 3}\n",
    "# Rolling a die: {1, 2, 3, 4, 5, 6}\n",
    "# Number of customers per hour: {0, 1, 2, ...}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1b99d0-de3e-4261-8801-fb35c825343f",
   "metadata": {},
   "source": [
    "*  Continuous Random Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "90544765-b4d7-4650-9b6d-6ff14ca71549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Height of a person: (0, âˆž)\n",
    "# Temperature: (-âˆž, âˆž)\n",
    "# Time waiting in line: [0, âˆž)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e899b182-1738-4aaa-af67-36a4531f8853",
   "metadata": {},
   "source": [
    "Key Points to Remember:\n",
    "\n",
    "1. Always specify whether you're dealing with discrete or continuous\n",
    "2. Know the probability distribution\n",
    "3. Understand the parameters (mean, variance)\n",
    "4. Consider the sample space (possible values)\n",
    "5. Be clear about probability calculations (PMF vs PDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e91fb-d96f-4179-a25d-96a5837c1fd2",
   "metadata": {},
   "source": [
    "## Short summary (Random variable)\n",
    "\n",
    "A Random Variable is a variable whose values are determined by chance or random processes. Here's a simple breakdown:\n",
    "\n",
    "1. Basic Definition:\n",
    "- A function that assigns numerical values to outcomes of a random experiment\n",
    "- Like a messenger that converts random outcomes into numbers\n",
    "\n",
    "2. Types:\n",
    "- Discrete: Takes specific, countable values\n",
    "  * Example: Number of heads in coin flips (0,1,2,3...)\n",
    "  * Example: Dice rolls (1,2,3,4,5,6)\n",
    "\n",
    "- Continuous: Takes any value within a range\n",
    "  * Example: Height of people\n",
    "  * Example: Temperature\n",
    "  * Example: Time duration\n",
    "\n",
    "3. Key Properties:\n",
    "- Expected Value (Mean): Average value in long run\n",
    "- Variance: Spread around the mean\n",
    "- Probability Distribution: How likely each value is\n",
    "\n",
    "4. Common Examples:\n",
    "- Coin flips (Discrete)\n",
    "- Weather temperature (Continuous)\n",
    "- Number of customers per hour (Discrete)\n",
    "- Stock prices (Continuous)\n",
    "\n",
    "5. Common Distributions:\n",
    "- Normal (Bell curve): Height, IQ scores\n",
    "- Binomial: Success/failure experiments\n",
    "- Poisson: Rate of events (customers arriving)\n",
    "- Uniform: Equal chance for all values\n",
    "\n",
    "The key is that random variables help us quantify uncertainty and make predictions about random processes in a mathematical way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9785690d-35cc-4581-83b9-0e356e4e02e2",
   "metadata": {},
   "source": [
    "# Z-Table, T-Table\n",
    "\n",
    "Here's a simple explanation of t-table and z-table contents:\n",
    "\n",
    "Z-TABLE:\n",
    "1. Contains Standard Normal Distribution probabilities\n",
    "2. Values show area under curve (probability)\n",
    "3. For standardized values (mean=0, SD=1)\n",
    "4. Contents:\n",
    "   - Left column: z-score to 1 decimal (e.g., 1.2)\n",
    "   - Top row: second decimal (e.g., .03)\n",
    "   - Body: probability values\n",
    "   - Example: z=1.23 â†’ find where 1.2 row meets .03 column\n",
    "\n",
    "T-TABLE:\n",
    "1. Similar to z-table but accounts for small samples\n",
    "2. More spread out than z-distribution\n",
    "3. Contents:\n",
    "   - Left column: Degrees of Freedom (df = n-1)\n",
    "   - Top row: Probability levels (Î±) like 0.05, 0.025\n",
    "   - Body: Critical t-values\n",
    "   - Example: df=10, Î±=0.05 â†’ find where row 10 meets 0.05 column\n",
    "\n",
    "Key Differences:\n",
    "1. Z-table: Used for large samples (n>30)\n",
    "2. T-table: Used for small samples (n<30)\n",
    "3. Z-table: One standard distribution\n",
    "4. T-table: Different distributions based on df\n",
    "5. Z-table: Area/probability values\n",
    "6. T-table: Critical values\n",
    "\n",
    "When to Use:\n",
    "- Z-table: Large samples, known population SD\n",
    "- T-table: Small samples, unknown population SD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514f0638-d37a-447c-9a52-3b91e23fdb52",
   "metadata": {},
   "source": [
    "# F-Table, Chi-Square Table:\n",
    "\n",
    "Here's a simple explanation of Chi-Square and F-tables:\n",
    "\n",
    "CHI-SQUARE TABLE:\n",
    "1. Values are critical values of chi-square distribution\n",
    "2. Contents:\n",
    "   - Left column: Degrees of Freedom (df)\n",
    "   - Top row: Significance levels (Î±) like 0.05, 0.01\n",
    "   - Body: Critical chi-square values\n",
    "   - Example: df=5, Î±=0.05 â†’ find where row 5 meets 0.05 column\n",
    "\n",
    "Used for:\n",
    "- Goodness of fit tests\n",
    "- Independence tests\n",
    "- Homogeneity tests\n",
    "- Larger value = more evidence against null hypothesis\n",
    "\n",
    "F-TABLE:\n",
    "1. Contains critical values for F-distribution\n",
    "2. Contents:\n",
    "   - Left column: dfâ‚ (numerator df)\n",
    "   - Top row: dfâ‚‚ (denominator df)\n",
    "   - Multiple tables for different Î± levels (usually 0.05, 0.01)\n",
    "   - Example: dfâ‚=4, dfâ‚‚=20, Î±=0.05 â†’ find where row 4 meets column 20\n",
    "\n",
    "Used for:\n",
    "- ANOVA (Analysis of Variance)\n",
    "- Comparing variances\n",
    "- Regression analysis\n",
    "- Model comparisons\n",
    "\n",
    "Key Differences:\n",
    "1. Chi-square: One df value\n",
    "2. F-table: Two df values (dfâ‚, dfâ‚‚)\n",
    "3. Chi-square: Tests categorical data\n",
    "4. F-table: Tests variance ratios\n",
    "5. Chi-square: Always positive\n",
    "6. F-table: Used for comparing two variances\n",
    "\n",
    "When to Use:\n",
    "- Chi-square: Categorical data analysis\n",
    "- F-table: Comparing variances, ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce42b5eb-f52c-4c0a-aa71-e21f738246ae",
   "metadata": {},
   "source": [
    "# Critical Values in Z, T, F, and Chi-Square Tables\n",
    "1. What is a Critical Value?\n",
    "A critical value is a cutoff point that defines regions where a test statistic is unlikely to lie under the null hypothesis. These values are based on the chosen significance level (\n",
    "ð›¼\n",
    "Î±) of the test, which represents the probability of rejecting the null hypothesis when it is true (Type I error).\n",
    "\n",
    "For a test statistic:\n",
    "\n",
    "- If it lies beyond the critical value, the null hypothesis is rejected.\n",
    "- If it lies within the critical region, it suggests statistical significance.\n",
    "\n",
    "\n",
    "We reject the null hypothesis if the test statistic exceeds (is more extreme than) the critical value.\n",
    "\n",
    "We reject the null hypothesis if the p-value is less than the significance level (\n",
    "ð›¼\n",
    "Î±)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba820e-5773-461f-ba2e-1a49756d624a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Derivative\n",
    "In mathematics, a derivative is a measure of how a function changes as its input changes. Specifically:\n",
    "\n",
    "1. It represents the instantaneous rate of change of a function with respect to one of its variables.\n",
    "\n",
    "2. Graphically, the derivative at a point is the slope of the tangent line to the function's curve at that point.\n",
    "\n",
    "3. In calculus, it's calculated using limits, typically through the formula: \n",
    "   f'(x) = lim[hâ†’0] (f(x+h) - f(x)) / h\n",
    "\n",
    "4. Derivatives have crucial applications in:\n",
    "   - Physics (calculating velocity and acceleration)\n",
    "   - Economics (analyzing rates of change in economic variables)\n",
    "   - Engineering (optimization and rate of change problems)\n",
    "   - Machine learning (gradient descent algorithms)\n",
    "\n",
    "Common notation for derivatives include f'(x), dy/dx, or âˆ‚f/âˆ‚x, depending on the context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e94a6d2-8c76-46f2-8f9e-9f78609e7cf8",
   "metadata": {},
   "source": [
    "# Partial Derivative\n",
    "A partial derivative is a type of derivative taken with respect to one variable while treating other variables as constants. Key points:\n",
    "\n",
    "1. Used in multivariable calculus to understand how a function changes when one variable changes while others remain fixed.\n",
    "\n",
    "2. Notation: âˆ‚f/âˆ‚x means the partial derivative of function f with respect to x.\n",
    "\n",
    "3. Calculated by treating all other variables as constants and differentiating the function as if it were a single-variable function.\n",
    "\n",
    "4. Critical in fields like:\n",
    "   - Physics (thermodynamics, fluid dynamics)\n",
    "   - Engineering (stress analysis)\n",
    "   - Economics (multivariate optimization)\n",
    "   - Machine learning (gradient calculations)\n",
    "\n",
    "Example: For f(x,y) = xÂ²y, âˆ‚f/âˆ‚x = 2xy, and âˆ‚f/âˆ‚y = xÂ²."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3974ae6b-e0d5-4ccf-9dcf-bbb82c879a64",
   "metadata": {},
   "source": [
    "# Partial Derivatives\n",
    "A partial derivative measures how a function changes with respect to one variable while keeping other variables constant. Here's a simple explanation:\n",
    "\n",
    "1. Basic Concept:\n",
    "- Takes derivative with respect to one variable\n",
    "- Treats other variables as constants\n",
    "- Symbol: âˆ‚f/âˆ‚x (read as \"partial f with respect to x\")\n",
    "\n",
    "2. Key Points:\n",
    "- Used for functions with multiple variables\n",
    "- Like regular derivative but focuses on one variable\n",
    "- Different partial derivatives for each variable\n",
    "\n",
    "3. Common Notation:\n",
    "- âˆ‚f/âˆ‚x or fx: partial with respect to x\n",
    "- âˆ‚f/âˆ‚y or fy: partial with respect to y\n",
    "- âˆ‚Â²f/âˆ‚xÂ² or fxx: second partial derivative\n",
    "\n",
    "4. Example Function: f(x,y) = xÂ² + xy + yÂ²\n",
    "   \n",
    "   Partial Derivatives:\n",
    "   - âˆ‚f/âˆ‚x = 2x + y (treat y as constant)\n",
    "   - âˆ‚f/âˆ‚y = x + 2y (treat x as constant)\n",
    "\n",
    "5. Applications:\n",
    "- Optimization problems\n",
    "- Gradient calculations\n",
    "- Rate of change in multivariable systems\n",
    "- Vector calculus\n",
    "- Physics equations\n",
    "- Economic models\n",
    "\n",
    "6. Geometric Meaning:\n",
    "- Slope of curve in specific direction\n",
    "- Rate of change along one axis\n",
    "- Tangent line parallel to variable axis\n",
    "\n",
    "Remember: When taking partial derivative, treat all other variables as constants and apply regular derivative rules to the chosen variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f7a2e3-7e6d-4094-b8e3-3ff5a48a9de3",
   "metadata": {},
   "source": [
    "# coefficient\n",
    "A coefficient is a numerical or constant factor that multiplies a variable in an algebraic expression. For example:\n",
    "\n",
    "1. In the equation 3x + 2, 3 is the coefficient of x\n",
    "2. In the polynomial 5xÂ²y, 5 is the coefficient of xÂ²y\n",
    "3. Coefficients can be whole numbers, fractions, or decimals\n",
    "4. They indicate the scale or magnitude of a variable's contribution in an equation\n",
    "\n",
    "Common in mathematics, science, and engineering for representing relationships between quantities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253ae71-d7c0-4a93-8eea-246355be0da0",
   "metadata": {},
   "source": [
    "# Determinant \n",
    "A determinant is a special number calculated from a square matrix that provides important information about the matrix's properties. Here are the key points:\n",
    "\n",
    "1. Basic Properties:\n",
    "   - Only defined for square matrices (same number of rows and columns)\n",
    "   - Results in a single number\n",
    "   - Denoted as |A| or det(A) for a matrix A\n",
    "\n",
    "2. For small matrices:\n",
    "   - 2Ã—2 matrix: |A| = ad - bc, where A = [a b; c d]\n",
    "   - 3Ã—3 matrix: Uses Sarrus' rule or expansion by minors\n",
    "\n",
    "3. Important Applications:\n",
    "   - Determines if a matrix is invertible (determinant â‰  0)\n",
    "   - Calculates area/volume transformations\n",
    "   - Solves systems of linear equations\n",
    "   - Finds eigenvalues\n",
    "\n",
    "4. Key Properties:\n",
    "   - det(AB) = det(A) Ã— det(B)\n",
    "   - det(AT) = det(A)\n",
    "   - If det(A) = 0, the matrix is singular (non-invertible)\n",
    "   - For triangular matrices, determinant is product of diagonal elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688eee59-bbf2-4072-93fb-6aa120c533ec",
   "metadata": {},
   "source": [
    "# 400 series Http status code\n",
    "The 400 series of HTTP status codes, also known as 4xx status codes, are Client Error responses. They indicate that there's a problem with the request sent by the client (browser/application), not with the server itself.\n",
    "\n",
    "Key characteristics of 400 series status codes:\n",
    "\n",
    "1. Client-side errors: The problem is on the requesting side, meaning the client needs to modify the request to get a successful response\n",
    "\n",
    "2. Contrast with other series:\n",
    "   - 2xx (Success): Request succeeded\n",
    "   - 3xx (Redirection): Further action needed to complete request\n",
    "   - 4xx (Client Error): Client made a mistake\n",
    "   - 5xx (Server Error): Server failed to fulfill a valid request\n",
    "\n",
    "3. Common scenarios for 400 errors:\n",
    "   - Missing authentication\n",
    "   - Insufficient permissions\n",
    "   - Requesting non-existent resources\n",
    "   - Using wrong HTTP methods\n",
    "   - Malformed requests\n",
    "   - Invalid parameters or headers\n",
    "\n",
    "The core message of any 4xx response is \"You (the client) did something wrong in your request, and you need to fix it before trying again.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8392f89-469f-4b3c-adc8-086c23555eea",
   "metadata": {},
   "source": [
    "# The **ACID** properties \n",
    "The **ACID** properties in SQL are a set of principles that ensure reliable and consistent transactions in a database management system. They stand for:\n",
    "\n",
    "---\n",
    "\n",
    "### **ACID Properties:**\n",
    "1. **Atomicity**:\n",
    "   - Ensures that a transaction is treated as a single \"unit of work.\"\n",
    "   - Either all the operations within a transaction are completed, or none of them are.\n",
    "   - If any operation in the transaction fails, the entire transaction is rolled back.\n",
    "   - Example: \n",
    "     - Transferring money between two bank accounts should debit one account and credit another. If either fails, neither operation should take place.\n",
    "\n",
    "---\n",
    "\n",
    "2. **Consistency**:\n",
    "   - Guarantees that a transaction brings the database from one valid state to another.\n",
    "   - Ensures that all integrity constraints are satisfied after the transaction.\n",
    "   - Example:\n",
    "     - In a banking system, the total balance before and after a transfer operation should remain consistent.\n",
    "\n",
    "---\n",
    "\n",
    "3. **Isolation**:\n",
    "   - Ensures that multiple transactions can execute concurrently without interfering with each other.\n",
    "   - Changes made by one transaction are not visible to other transactions until they are committed.\n",
    "   - Example:\n",
    "     - Two customers booking the last ticket for a flight should not both succeed. Proper isolation prevents such conflicts.\n",
    "\n",
    "---\n",
    "\n",
    "4. **Durability**:\n",
    "   - Guarantees that once a transaction is committed, the changes are permanent, even in the case of system failure.\n",
    "   - Example:\n",
    "     - After a successful money transfer, the changes in account balances should persist, even if the database crashes immediately afterward.\n",
    "\n",
    "---\n",
    "\n",
    "### **ACID in Practice**:\n",
    "- **Atomicity** is achieved through mechanisms like transaction logs.\n",
    "- **Consistency** is maintained by enforcing constraints like foreign keys and triggers.\n",
    "- **Isolation** levels (e.g., Serializable, Repeatable Read) are set to control how transactions interact.\n",
    "- **Durability** is ensured using techniques like write-ahead logging and backups.\n",
    "\n",
    "---\n",
    "\n",
    "### **Example of an SQL Transaction with ACID Properties**:\n",
    "```sql\n",
    "START TRANSACTION;\n",
    "\n",
    "-- Step 1: Deduct money from Account A\n",
    "UPDATE accounts\n",
    "SET balance = balance - 100\n",
    "WHERE account_id = 'A';\n",
    "\n",
    "-- Step 2: Add money to Account B\n",
    "UPDATE accounts\n",
    "SET balance = balance + 100\n",
    "WHERE account_id = 'B';\n",
    "\n",
    "-- Commit the transaction to make changes permanent\n",
    "COMMIT;\n",
    "\n",
    "-- If any step fails, roll back the transaction\n",
    "ROLLBACK;\n",
    "```\n",
    "- If the database crashes or any operation fails, `ROLLBACK` ensures the database returns to its previous state (Atomicity).\n",
    "- The constraints ensure the balances remain consistent (Consistency).\n",
    "- While this transaction is running, other transactions are isolated (Isolation).\n",
    "- After committing, the changes remain even after a crash (Durability).\n",
    "\n",
    "--- \n",
    "These principles are critical for reliable database operations in scenarios like banking, e-commerce, and inventory systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2690fc02-de01-4555-8223-d9edeb0be7bb",
   "metadata": {},
   "source": [
    "# Transaction\n",
    "\n",
    "A transaction in SQL is a sequence of one or more operations (like INSERT, UPDATE, or DELETE) that are executed as a single unit of work. It ensures that either all the operations are successfully completed (commit) or none of them take effect (rollback) if something goes wrong.\n",
    "\n",
    "\n",
    "In the context of databases, a **transaction** is a sequence of one or more operations (queries, updates, or other database actions) that are executed as a single unit of work. A transaction must be completed in full or not executed at all. This ensures data consistency and integrity.\n",
    "\n",
    "### **Key Characteristics of a Transaction** (ACID Properties)\n",
    "\n",
    "A transaction follows the **ACID** properties to ensure reliable and consistent database operations:\n",
    "\n",
    "1. **Atomicity**: \n",
    "   - A transaction is atomic, meaning it is indivisible. All operations in the transaction must be completed successfully. If any part of the transaction fails, the entire transaction is rolled back.\n",
    "   - **Example**: If a money transfer transaction between two bank accounts fails halfway, all changes (such as debiting one account and crediting another) are rolled back, ensuring no partial updates.\n",
    "\n",
    "2. **Consistency**:\n",
    "   - A transaction brings the database from one valid state to another. It ensures that data is always valid according to the rules (such as constraints, triggers, etc.) defined in the database.\n",
    "   - **Example**: If a database enforces that the balance of an account cannot be negative, a transaction that tries to withdraw more money than available will fail, maintaining consistency.\n",
    "\n",
    "3. **Isolation**:\n",
    "   - Transactions are isolated from each other. The intermediate state of a transaction is invisible to other transactions until the transaction is completed (committed).\n",
    "   - **Example**: If two users try to update the same record simultaneously, one user's transaction will wait until the other is finished, preventing data conflicts.\n",
    "\n",
    "4. **Durability**:\n",
    "   - Once a transaction is committed, its changes are permanent, even in the case of system crashes. The database ensures that committed data is saved to permanent storage.\n",
    "   - **Example**: After a successful transaction, even if the system crashes, the data is not lost.\n",
    "\n",
    "### **Transaction Workflow**\n",
    "\n",
    "1. **Start**: A transaction begins.\n",
    "2. **Operations**: Multiple database operations (such as INSERT, UPDATE, DELETE) are performed.\n",
    "3. **Commit**: If all operations are successful, the transaction is committed, making the changes permanent.\n",
    "4. **Rollback**: If any operation fails, the transaction is rolled back, and all changes are undone.\n",
    "\n",
    "---\n",
    "\n",
    "### **SQL Syntax for Transactions**\n",
    "\n",
    "1. **Begin a Transaction**:\n",
    "   ```sql\n",
    "   BEGIN TRANSACTION;\n",
    "   ```\n",
    "\n",
    "2. **Commit a Transaction** (save the changes to the database):\n",
    "   ```sql\n",
    "   COMMIT;\n",
    "   ```\n",
    "\n",
    "3. **Rollback a Transaction** (undo the changes made during the transaction):\n",
    "   ```sql\n",
    "   ROLLBACK;\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### **Example of a Transaction**\n",
    "\n",
    "Let's say we want to transfer money from one bank account to another. The transaction involves two steps:\n",
    "1. Deducting money from the source account.\n",
    "2. Adding money to the destination account.\n",
    "\n",
    "```sql\n",
    "BEGIN TRANSACTION;\n",
    "\n",
    "-- Step 1: Deduct from source account\n",
    "UPDATE accounts SET balance = balance - 100 WHERE account_id = 'A';\n",
    "\n",
    "-- Step 2: Add to destination account\n",
    "UPDATE accounts SET balance = balance + 100 WHERE account_id = 'B';\n",
    "\n",
    "-- If both operations succeed, commit the transaction\n",
    "COMMIT;\n",
    "```\n",
    "\n",
    "If something goes wrong (e.g., insufficient funds), the transaction can be rolled back:\n",
    "\n",
    "```sql\n",
    "-- If an error occurs, rollback all changes\n",
    "ROLLBACK;\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **Why are Transactions Important?**\n",
    "- **Data Integrity**: Ensures that all database changes are consistent and reliable.\n",
    "- **Concurrency Control**: Allows multiple users to access the database without causing conflicts or data corruption.\n",
    "- **Error Recovery**: Ensures that incomplete or erroneous operations do not affect the database's state.\n",
    "\n",
    "Let me know if you'd like more examples or deeper explanations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0213ef10-6db3-4364-afbd-0875a0924862",
   "metadata": {},
   "source": [
    "# 1nf, 2nf, 3nf\n",
    "Here are the key points for each normal form:\n",
    "\n",
    "1. First Normal Form (1NF):\n",
    "- Each cell must have a single value (atomic values)\n",
    "- Each record must be unique\n",
    "- Each column must have same data type\n",
    "- No repeating groups\n",
    "- Must have a primary key\n",
    "\n",
    "2. Second Normal Form (2NF):\n",
    "- Must be in 1NF first\n",
    "- All non-key attributes must fully depend on the entire primary key\n",
    "- No partial dependencies\n",
    "- Remove attributes that depend on only part of the primary key\n",
    "\n",
    "3. Third Normal Form (3NF):\n",
    "- Must be in 2NF first\n",
    "- No transitive dependencies\n",
    "- Non-key attributes cannot depend on other non-key attributes\n",
    "- All fields must depend directly on the primary key\n",
    "\n",
    "Benefits of Normalization:\n",
    "- Reduces data redundancy\n",
    "- Ensures data consistency\n",
    "- Improves data integrity\n",
    "- Makes database more organized\n",
    "- Saves storage space\n",
    "- Easier maintenance\n",
    "- Better database structure\n",
    "\n",
    "Would you like me to elaborate on any of these points?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758139c8-53c3-4096-894a-48dd9993da01",
   "metadata": {},
   "source": [
    "# Complexity of recurssion\n",
    "Key Notes:\n",
    "* Exponential Time (\n",
    "ð‘‚\n",
    "(\n",
    "2\n",
    "ð‘›\n",
    ")\n",
    "O(2 \n",
    "n\n",
    " )): Occurs in cases like binary recursion without memoization (e.g., Fibonacci).\n",
    "* Logarithmic Time (\n",
    "ð‘‚\n",
    "(\n",
    "log\n",
    "â¡\n",
    "ð‘›\n",
    ")\n",
    "O(logn)): Happens when the problem size reduces exponentially, e.g., binary search.\n",
    "* Polynomial Time (\n",
    "ð‘‚\n",
    "(\n",
    "ð‘›\n",
    "ð‘˜\n",
    ")\n",
    "O(n \n",
    "k\n",
    " )): Depends on the division and combination of subproblems.\n",
    "\n",
    "Efficient recursion often involves memoization or dynamic programming to reduce redundant calls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98b6647-ff09-41cf-b22e-8743fe23acce",
   "metadata": {},
   "source": [
    "# Sum of alpha numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "17a95dcc-18cc-46f7-8165-00e7d62cd2e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "def total_sum(arr):\n",
    "    return sum(i for i in arr if isinstance(i, int))\n",
    "\n",
    "\n",
    "arr = ['a', 'b', 1, 'k', 3, 'd', 2]\n",
    "result = total_sum(arr)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee917e93-b7c9-4d52-bdca-08f7a6bc72f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample code for integer inside string\n",
    "arrs = ['a', 'b', '1', 'k', '3', 'd', '2']\n",
    "sum(int(i) for i in arrs if i.isdigit())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8855e0bd-774f-4033-a730-0a6ac873915f",
   "metadata": {},
   "source": [
    "#  Loss Function\n",
    "A loss function in machine learning is a mathematical method to measure how far a model's predictions are from the actual results. It quantifies the error between predicted and true values, serving as a key mechanism for training models by:\n",
    "\n",
    "1. Purpose\n",
    "- Measuring prediction accuracy\n",
    "- Guiding model optimization\n",
    "- Helping the model learn from mistakes\n",
    "\n",
    "2. Core Mechanism\n",
    "- Calculates difference between predicted and actual outputs\n",
    "- Provides a single numerical value representing error\n",
    "- Lower loss indicates better model performance\n",
    "\n",
    "3. Role in Training\n",
    "- Used by optimization algorithms (like gradient descent)\n",
    "- Helps adjust model parameters\n",
    "- Minimizes error during learning process\n",
    "\n",
    "4. Types Vary by Problem\n",
    "- Classification: Cross-entropy loss\n",
    "- Regression: Mean squared error\n",
    "- Object detection: Intersection over Union (IoU)\n",
    "\n",
    "5. Key Characteristics\n",
    "- Always non-negative\n",
    "- Lower values mean better predictions\n",
    "- Differentiable to enable gradient-based optimization\n",
    "\n",
    "Essentially, a loss function is the \"learning signal\" that tells a machine learning model how to improve its predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75222651-8451-4da6-9156-2f3ce0ae2b12",
   "metadata": {},
   "source": [
    "## Formula \n",
    "Loss Function Formulas:\n",
    "\n",
    "1. Mean Squared Error (Regression)\n",
    "- Formula: L = (1/n) * Î£(y - Å·)Â²\n",
    "- n = number of samples\n",
    "- y = actual value\n",
    "- Å· = predicted value\n",
    "\n",
    "2. Binary Cross-Entropy (Binary Classification)\n",
    "- Formula: L = -[y * log(p) + (1-y) * log(1-p)]\n",
    "- y = true label (0 or 1)\n",
    "- p = predicted probability\n",
    "\n",
    "3. Categorical Cross-Entropy (Multi-Class)\n",
    "- Formula: L = -Î£(y_i * log(p_i))\n",
    "- y_i = true label (one-hot encoded)\n",
    "- p_i = predicted probability for each class\n",
    "\n",
    "4. Hinge Loss (SVM)\n",
    "- Formula: L = max(0, 1 - y * Å·)\n",
    "- y = true label (-1 or 1)\n",
    "- Å· = predicted value\n",
    "\n",
    "5. Mean Absolute Error\n",
    "- Formula: L = (1/n) * Î£|y - Å·|\n",
    "- Measures average absolute difference\n",
    "\n",
    "Each formula aims to quantify prediction error, guiding model improvement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1869c76-49fb-44aa-baa8-863e0f3b4247",
   "metadata": {},
   "source": [
    "# Cost Function vs Loss Function:\n",
    "\n",
    "1. Differences:\n",
    "- Loss Function: Calculates error for individual training example\n",
    "- Cost Function: Calculates total error across entire training dataset\n",
    "\n",
    "2. Cost Function Characteristics:\n",
    "- Aggregates loss across all training samples\n",
    "- Used to evaluate overall model performance\n",
    "- Typically average of individual losses\n",
    "- Guides optimization of model parameters\n",
    "\n",
    "3. Common Cost Function Formulas:\n",
    "- Average of Mean Squared Error\n",
    "- Total Cross-Entropy Loss\n",
    "- Regularized Loss (includes penalty terms)\n",
    "\n",
    "4. Purpose:\n",
    "- Provides comprehensive measure of model's predictive performance\n",
    "- Helps minimize total error during training\n",
    "- Determines how well model generalizes\n",
    "\n",
    "Key Insight: Cost function is essentially an aggregated loss function used to understand and improve model's overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd049db-a078-4e83-89fe-7a099fdcaf0e",
   "metadata": {},
   "source": [
    "# **Precision and Accuracy in Machine Learning**\n",
    "\n",
    "Precision and accuracy are two key metrics used to evaluate the performance of machine learning models. While they are related, they measure different aspects of a model's performance.\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Precision**\n",
    "**Definition**:  \n",
    "Precision measures the proportion of correctly predicted positive instances (True Positives) out of all instances predicted as positive (True Positives + False Positives). It indicates the model's ability to avoid false alarms.\n",
    "\n",
    "**Formula**:\n",
    "\n",
    "**TP/TP+FP**\n",
    "\n",
    "**Use Case**:  \n",
    "- Useful when **false positives** are costly, such as in spam detection, where you want to avoid marking legitimate emails as spam.\n",
    "\n",
    "**Example**:  \n",
    "If a model predicts 100 emails as spam, and 80 of those are actually spam, precision is:\n",
    "\\[\n",
    "\\text{Precision} = \\frac{80}{80 + 20} = 0.8 \\text{ (80%)}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Accuracy**\n",
    "**Definition**:  \n",
    "Accuracy measures the proportion of correctly predicted instances (both positive and negative) out of the total number of instances.\n",
    "\n",
    "**Formula**:\n",
    "\n",
    "**TP+TN/TOTAL PREDICTIONS**\n",
    "\n",
    "\n",
    "**Use Case**:  \n",
    "- Useful when the dataset is balanced (roughly equal number of positive and negative instances).\n",
    "\n",
    "**Example**:  \n",
    "If a model makes 1,000 predictions, out of which 900 are correct, accuracy is:\n",
    "\\[\n",
    "\\text{Accuracy} = \\frac{900}{1000} = 0.9 \\text{ (90%)}\n",
    "\\]\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **Key Differences Between Precision and Accuracy**\n",
    "\n",
    "| **Metric**       | **Focus**                                   | **Best Used When**                               |\n",
    "|-------------------|--------------------------------------------|-------------------------------------------------|\n",
    "| **Precision**     | Quality of positive predictions            | False positives are costly (e.g., spam detection) |\n",
    "| **Accuracy**      | Overall correctness of predictions         | Dataset is balanced with equal positives/negatives |\n",
    "\n",
    "---\n",
    "\n",
    "## **Precision vs. Accuracy Example**\n",
    "Consider a model predicting whether a person has a disease:\n",
    "- **Precision**: Of all the people the model predicted as having the disease, how many truly have it?\n",
    "- **Accuracy**: Out of the entire population tested, how many predictions (positive and negative) were correct?\n",
    "\n",
    "---\n",
    "\n",
    "## **In Imbalanced Datasets**\n",
    "When the dataset is imbalanced (e.g., 95% negative, 5% positive), accuracy can be misleading. For example:\n",
    "- A model predicting all instances as negative will achieve 95% accuracy but will have 0% precision for the positive class.\n",
    "- Precision and metrics like recall or F1-score are more informative in such cases.\n",
    "\n",
    "By understanding precision and accuracy, you can better assess a model's performance based on the specific problem at hand.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ee797-246f-4168-b61d-393f3431479e",
   "metadata": {},
   "source": [
    "# Axis based operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63bc6873-e92d-414b-8686-240a05e1da88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  1  4  7\n",
      "1  2  5  8\n",
      "2  3  6  9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4c1b0e4b-cac8-41e0-a2fe-272e2cd4c9b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A     6\n",
       "B    15\n",
       "C    24\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f6d8920d-c33f-43ec-9f8d-62f2966d5f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12\n",
       "1    15\n",
       "2    18\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a5922c16-6109-4239-acc7-504570d086af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['A'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "87f99412-3f1c-49dd-a32a-5976fd13f695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "arr = np.array([[1,2,1],\n",
    "               [2,3,4],\n",
    "               [3,4,5]])\n",
    "\n",
    "first_col_sum = arr[:, 0].sum() # first row\n",
    "first_col_sum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "70015355-19c6-447f-859f-0fc81e852ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_col_sum = arr[:, 1].sum()\n",
    "second_col_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "de8a3391-299d-492d-a081-7ebb75781fa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_row_sum = arr[0, :].sum()\n",
    "first_row_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34be5610-bf41-4b0d-9ec8-2a4b75f63f46",
   "metadata": {},
   "source": [
    "# Types of Matrices:\n",
    "\n",
    "1. Based on Shape\n",
    "- Square Matrix (rows = columns)\n",
    "- Rectangular Matrix (rows â‰  columns)\n",
    "- Row Matrix (1 row)\n",
    "- Column Matrix (1 column)\n",
    "\n",
    "2. Based on Elements\n",
    "- Diagonal Matrix (non-zero elements only on diagonal)\n",
    "- Zero/Null Matrix (all elements are zero)\n",
    "- Identity Matrix (1s on diagonal, 0s elsewhere)\n",
    "- Scalar Matrix (same number on diagonal)\n",
    "- Sparse Matrix (mostly zeros)\n",
    "- Dense Matrix (mostly non-zeros)\n",
    "\n",
    "3. Special Types\n",
    "- Symmetric Matrix (equal to its transpose)\n",
    "- Skew-symmetric Matrix (negative of its transpose)\n",
    "- Upper Triangular (zeros below diagonal)\n",
    "- Lower Triangular (zeros above diagonal)\n",
    "- Orthogonal Matrix (inverse equals transpose)\n",
    "- Singular Matrix (determinant = 0)\n",
    "- Non-singular Matrix (determinant â‰  0)\n",
    "\n",
    "4. Based on Properties\n",
    "- Binary Matrix (elements are 0 or 1)\n",
    "- Boolean Matrix (used in logical operations)\n",
    "- Complex Matrix (complex number elements)\n",
    "- Toeplitz Matrix (constant diagonals)\n",
    "- Hermitian Matrix (complex conjugate transpose)\n",
    "\n",
    "5. Based on Operations\n",
    "- Inverse Matrix\n",
    "- Transpose Matrix\n",
    "- Adjoint Matrix\n",
    "- Conjugate Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b1acf8-64e0-4bea-8cf4-23e4e20c9cf4",
   "metadata": {},
   "source": [
    "# Types of Transformations:\n",
    "\n",
    "1. Linear Transformations\n",
    "- Rotation\n",
    "- Scaling\n",
    "- Reflection\n",
    "- Shear\n",
    "- Translation (not strictly linear)\n",
    "- Projection\n",
    "\n",
    "2. Geometric Transformations\n",
    "- Rigid/Isometric (preserves distance)\n",
    "   * Translation\n",
    "   * Rotation\n",
    "   * Reflection\n",
    "- Non-rigid\n",
    "   * Scaling\n",
    "   * Shear\n",
    "   * Stretching\n",
    "\n",
    "3. Coordinate Transformations\n",
    "- Cartesian to Polar\n",
    "- Polar to Cartesian\n",
    "- Spherical coordinates\n",
    "- Cylindrical coordinates\n",
    "\n",
    "4. Image Transformations\n",
    "- Affine (preserves parallel lines)\n",
    "- Perspective\n",
    "- Warping\n",
    "- Morphing\n",
    "\n",
    "5. Mathematical Transformations\n",
    "- Fourier Transform\n",
    "- Laplace Transform\n",
    "- Wavelet Transform\n",
    "- Z-Transform\n",
    "\n",
    "6. Properties Based Classification\n",
    "- One-to-one (Injective)\n",
    "- Onto (Surjective)\n",
    "- Bijective (Both one-to-one and onto)\n",
    "- Identity transformation\n",
    "- Inverse transformation\n",
    "\n",
    "7. Domain Based\n",
    "- Complex transformations\n",
    "- Real transformations\n",
    "- Vector transformations\n",
    "- Matrix transformations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da038aba-4837-4dc9-a402-f122a23cd70b",
   "metadata": {},
   "source": [
    "# Supervised Learning & Unsupervised Learning\n",
    "**Supervised Learning**:\n",
    "\n",
    "In **supervised learning**, the algorithm learns from labeled data. This means that each training example comes with a correct answer (label), and the model is trained to predict or classify based on these known labels.\n",
    "\n",
    "- **Example:** \n",
    "  - **Task:** Predicting house prices.\n",
    "  - **Training Data:** A dataset with features (like size, location, and number of rooms) and known house prices (labels).\n",
    "  - The model learns the relationship between the features and the price, and can then predict prices for new, unseen houses.\n",
    "\n",
    " **Unsupervised Learning**:\n",
    " \n",
    "In **unsupervised learning**, the algorithm is given data without labels. It tries to find hidden patterns or structure in the data on its own.\n",
    "\n",
    "- **Example:**\n",
    "  - **Task:** Grouping customers by purchasing behavior.\n",
    "  - **Training Data:** A dataset with customer data (age, spending habits, etc.) but no pre-defined labels.\n",
    "  - The model groups customers into clusters based on similarities in their data, without knowing what those groups are ahead of time.\n",
    "\n",
    "### Summary:\n",
    "- **Supervised Learning:** Uses labeled data (with answers).\n",
    "- **Unsupervised Learning:** Uses unlabeled data (finds patterns by itself)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064da1a4-4b37-492a-a175-c93c1b423c53",
   "metadata": {},
   "source": [
    "# Mahine learning workflow  \n",
    "The machine learning workflow is a structured process that guides the development and deployment of machine learning models. Here's an overview of the steps:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Define the Problem**\n",
    "   - **Goal:** Understand the problem you are trying to solve and clearly define the objectives.\n",
    "   - Tasks:\n",
    "     - Identify the problem type: Classification, regression, clustering, etc.\n",
    "     - Define the performance metric(s): Accuracy, RMSE, F1-score, etc.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Collect and Prepare Data**\n",
    "   - **Goal:** Gather and preprocess data to make it suitable for model building.\n",
    "   - Tasks:\n",
    "     - Data collection: From databases, APIs, web scraping, etc.\n",
    "     - Data cleaning: Handle missing values, duplicates, and errors.\n",
    "     - Data transformation:\n",
    "       - Feature engineering (e.g., create new features, encode categorical variables).\n",
    "       - Scaling and normalization.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Exploratory Data Analysis (EDA)**\n",
    "   - **Goal:** Understand the data distribution, identify patterns, and detect anomalies.\n",
    "   - Tasks:\n",
    "     - Use visualizations (e.g., histograms, scatter plots, heatmaps).\n",
    "     - Analyze relationships between features.\n",
    "     - Evaluate class imbalance (for classification problems).\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Split Data**\n",
    "   - **Goal:** Divide the data into training, validation, and testing sets.\n",
    "   - Tasks:\n",
    "     - Common splits: 70%-80% training, 10%-15% validation, 10%-15% testing.\n",
    "     - Stratified splitting for imbalanced datasets.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Select and Train Model(s)**\n",
    "   - **Goal:** Choose appropriate algorithms and train the model(s) on the training set.\n",
    "   - Tasks:\n",
    "     - Algorithm selection: Based on the problem and dataset characteristics.\n",
    "     - Training: Fit the model using the training data.\n",
    "     - Use libraries like scikit-learn, TensorFlow, or PyTorch.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Hyperparameter Tuning**\n",
    "   - **Goal:** Optimize the model's performance by fine-tuning hyperparameters.\n",
    "   - Tasks:\n",
    "     - Techniques: Grid search, random search, Bayesian optimization.\n",
    "     - Use validation data to evaluate performance.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Evaluate Model**\n",
    "   - **Goal:** Assess the modelâ€™s performance on unseen data.\n",
    "   - Tasks:\n",
    "     - Use the test set for final evaluation.\n",
    "     - Metrics:\n",
    "       - Classification: Accuracy, precision, recall, F1-score, ROC-AUC.\n",
    "       - Regression: Mean Squared Error (MSE), RÂ², Mean Absolute Error (MAE).\n",
    "     - Error analysis: Investigate incorrect predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### 8. **Deploy the Model**\n",
    "   - **Goal:** Integrate the model into a production environment.\n",
    "   - Tasks:\n",
    "     - Save the model (e.g., using `joblib`, `pickle`, or ONNX).\n",
    "     - Deployment options: Web app (e.g., Flask, FastAPI), cloud service (e.g., AWS, GCP, Azure).\n",
    "     - Monitor for drift and retrain as necessary.\n",
    "\n",
    "---\n",
    "\n",
    "### 9. **Monitor and Maintain**\n",
    "   - **Goal:** Ensure the model remains accurate and effective over time.\n",
    "   - Tasks:\n",
    "     - Track model performance with new data.\n",
    "     - Update the model when performance degrades.\n",
    "\n",
    "---\n",
    "\n",
    "Would you like to dive deeper into any of these steps?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5db09e-befb-4a48-be20-e72fa0e6d392",
   "metadata": {},
   "source": [
    "# Model selection \n",
    "**Model selection** in machine learning refers to choosing the best algorithm or model for a given problem based on its performance. The goal is to find a model that generalizes well to new, unseen data, and provides the best trade-off between bias (error from overly simplistic models) and variance (error from overly complex models).\n",
    "\n",
    "### Steps to Perform Model Selection:\n",
    "\n",
    "1. **Define the Problem**:\n",
    "   - Understand the type of problem you're solving (e.g., classification, regression, clustering).\n",
    "   - Determine the type of data you have (e.g., structured, text, images).\n",
    "\n",
    "2. **Choose Candidate Models**:\n",
    "   - Based on the problem and data, choose a few models to evaluate.\n",
    "   - For example, for classification, models could include logistic regression, decision trees, k-nearest neighbors (KNN), support vector machines (SVM), or random forests.\n",
    "\n",
    "3. **Prepare the Data**:\n",
    "   - Clean and preprocess the data (handle missing values, encode categorical features, normalize/standardize numerical features, etc.).\n",
    "   - Split the data into **training** and **test** sets (e.g., 80% for training, 20% for testing) or use **cross-validation**.\n",
    "\n",
    "4. **Train the Models**:\n",
    "   - Train each candidate model using the training data.\n",
    "   - You may need to tune hyperparameters (e.g., regularization strength, number of trees in a random forest) for each model to get optimal performance.\n",
    "\n",
    "5. **Evaluate Model Performance**:\n",
    "   - Assess model performance using metrics that are appropriate for your problem:\n",
    "     - **For classification**: Accuracy, precision, recall, F1-score, ROC-AUC, confusion matrix.\n",
    "     - **For regression**: Mean squared error (MSE), R-squared, mean absolute error (MAE).\n",
    "     - **For clustering**: Silhouette score, Davies-Bouldin index.\n",
    "   - Use **cross-validation** (e.g., k-fold cross-validation) to get a better estimate of model performance by training and testing on different subsets of the data.\n",
    "\n",
    "6. **Compare Models**:\n",
    "   - Compare the performance of the models based on the evaluation metrics.\n",
    "   - Consider the trade-off between **bias and variance**: Simple models may have high bias and low variance, while complex models may have low bias and high variance.\n",
    "\n",
    "7. **Choose the Best Model**:\n",
    "   - Select the model that provides the best performance according to your evaluation metrics. If performance is similar across models, consider other factors such as:\n",
    "     - **Interpretability:** How easy it is to understand the model?\n",
    "     - **Training time:** Does the model require too much computation?\n",
    "     - **Scalability:** Can the model handle large datasets?\n",
    "     - **Robustness:** Is the model sensitive to noise or outliers?\n",
    "\n",
    "8. **Test the Model**:\n",
    "   - Once youâ€™ve selected the best model, test it on the **test set** (data the model hasnâ€™t seen) to evaluate its ability to generalize to new data.\n",
    "\n",
    "---\n",
    "\n",
    "### Example of Model Selection Process:\n",
    "Suppose you're solving a **classification problem** (e.g., predicting if a customer will buy a product based on their features like age, income, etc.):\n",
    "\n",
    "1. **Define the Problem**: You are trying to predict a binary outcome (buy or not buy).\n",
    "2. **Choose Candidate Models**: Logistic regression, decision trees, and random forests.\n",
    "3. **Prepare the Data**: Clean the data, normalize the features, and split into training/test sets.\n",
    "4. **Train the Models**: Train all three models on the training data.\n",
    "5. **Evaluate Model Performance**: Use accuracy and ROC-AUC for evaluation.\n",
    "6. **Compare Models**: Compare their performances and choose the model with the highest ROC-AUC.\n",
    "7. **Choose the Best Model**: Select the random forest if it has the best performance and generalization.\n",
    "8. **Test the Model**: Evaluate it on the test set to confirm it generalizes well.\n",
    "\n",
    "---\n",
    "\n",
    "### Hyperparameter Tuning:\n",
    "Often, model performance can be improved by tuning hyperparameters (parameters that are not learned by the model, like the number of trees in a random forest). Common techniques for hyperparameter tuning include:\n",
    "- **Grid Search:** Exhaustively search through a manually specified subset of the hyperparameter space.\n",
    "- **Random Search:** Randomly sample from the hyperparameter space.\n",
    "- **Bayesian Optimization:** Use a probabilistic model to find the best hyperparameters.\n",
    "- **Cross-Validation:** Combine model selection and hyperparameter tuning by using cross-validation during the search process.\n",
    "\n",
    "### Conclusion:\n",
    "Model selection is an iterative process that involves experimenting with different algorithms, tuning their hyperparameters, and evaluating their performance using appropriate metrics. Itâ€™s important to balance complexity, performance, and interpretability to find the best model for your task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27058512-77e1-4e46-91f2-1d429596a5cc",
   "metadata": {},
   "source": [
    "# Cross Validation:\n",
    "\n",
    "1. Purpose\n",
    "- Evaluates model performance\n",
    "- Prevents overfitting\n",
    "- Tests model generalization\n",
    "- Provides robust error estimation\n",
    "\n",
    "2. Common Types\n",
    "- K-Fold Cross Validation\n",
    "   * Splits data into k parts\n",
    "   * Uses k-1 folds for training\n",
    "   * Uses 1 fold for testing\n",
    "   * Repeats k times\n",
    "\n",
    "- Leave One Out (LOOCV)\n",
    "   * Special case of k-fold\n",
    "   * k equals number of samples\n",
    "   * Computationally expensive\n",
    "\n",
    "- Stratified K-Fold\n",
    "   * Maintains class distribution\n",
    "   * Used for imbalanced datasets\n",
    "\n",
    "- Hold-out Method\n",
    "   * Simple train-test split\n",
    "   * Not technically cross-validation\n",
    "   * Used for large datasets\n",
    "\n",
    "3. Advantages\n",
    "- Better assessment of model\n",
    "- Reduces overfitting\n",
    "- More reliable results\n",
    "- Uses all data efficiently\n",
    "\n",
    "4. Disadvantages\n",
    "- Computationally expensive\n",
    "- Time-consuming\n",
    "- May be slow for large datasets\n",
    "- Requires more resources\n",
    "\n",
    "5. When to Use\n",
    "- Small to medium datasets\n",
    "- Model comparison\n",
    "- Parameter tuning\n",
    "- Performance estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2402f4bc-4b47-42a4-8a00-792754d13d81",
   "metadata": {},
   "source": [
    "## Let me break down Cross Validation in detail:\n",
    "\n",
    "1. Definition\n",
    "- A resampling method to evaluate ML models\n",
    "- Tests how model will perform on unseen data\n",
    "- Helps validate model's stability\n",
    "\n",
    "2. Working Process\n",
    "- Step 1: Divide data into subsets (folds)\n",
    "- Step 2: Train model on some folds\n",
    "- Step 3: Test on remaining folds\n",
    "- Step 4: Rotate and repeat\n",
    "- Step 5: Average results\n",
    "\n",
    "3. K-Fold Example (with k=5)\n",
    "Round 1: [Test][Train][Train][Train][Train]\n",
    "Round 2: [Train][Test][Train][Train][Train]\n",
    "Round 3: [Train][Train][Test][Train][Train]\n",
    "Round 4: [Train][Train][Train][Test][Train]\n",
    "Round 5: [Train][Train][Train][Train][Test]\n",
    "\n",
    "4. Benefits\n",
    "- Better use of data\n",
    "- Reduces bias\n",
    "- More reliable accuracy\n",
    "- Helps in hyperparameter tuning\n",
    "- Prevents overfitting\n",
    "\n",
    "5. Common Applications\n",
    "- Model selection\n",
    "- Parameter tuning\n",
    "- Performance estimation\n",
    "- Comparing algorithms\n",
    "- Validating model stability\n",
    "\n",
    "6. When to Choose Each Type\n",
    "- K-Fold: General purpose, balanced datasets\n",
    "- Stratified: Imbalanced classes\n",
    "- LOOCV: Very small datasets\n",
    "- Hold-out: Very large datasets\n",
    "\n",
    "7. Best Practices\n",
    "- Choose appropriate k value (usually 5 or 10)\n",
    "- Ensure random splitting\n",
    "- Maintain class distributions\n",
    "- Consider computational resources\n",
    "- Use stratified for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dfcdac-ea19-4132-a73e-33fddbd91466",
   "metadata": {},
   "source": [
    "# Here are the main Validation Techniques:\n",
    "\n",
    "1. Hold-out Validation\n",
    "- Simple train-test split\n",
    "- Fixed validation set\n",
    "- Fastest method\n",
    "- Good for large datasets\n",
    "\n",
    "2. Cross-Validation\n",
    "- K-Fold CV\n",
    "- Stratified K-Fold\n",
    "- Leave-One-Out CV\n",
    "- Repeated K-Fold\n",
    "\n",
    "3. Time Series Validation\n",
    "- Forward Chaining\n",
    "- Rolling-window\n",
    "- Time-based splits\n",
    "- Walk-forward optimization\n",
    "\n",
    "4. Bootstrap Validation\n",
    "- Random sampling with replacement\n",
    "- Out-of-bag estimation\n",
    "- Good for small datasets\n",
    "- Multiple iterations\n",
    "\n",
    "5. Validation by Size\n",
    "- Train-Validation-Test split\n",
    "- 60-20-20 split common\n",
    "- 70-15-15 also used\n",
    "- 80-10-10 for small datasets\n",
    "\n",
    "6. Special Techniques\n",
    "- Nested Cross-validation\n",
    "- Group K-fold\n",
    "- Stratified Group K-fold\n",
    "- Monte Carlo CV\n",
    "\n",
    "Key Considerations:\n",
    "- Dataset size\n",
    "- Data distribution\n",
    "- Computational resources\n",
    "- Model complexity\n",
    "- Time constraints\n",
    "- Problem type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cc8f0a-92f1-42c1-a377-0be9b08c5b54",
   "metadata": {},
   "source": [
    "# Chatgpt pandas Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "146b72aa-24c4-4e90-b9f7-eb4412e79f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Math</th>\n",
       "      <th>English</th>\n",
       "      <th>Science</th>\n",
       "      <th>Grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alice</td>\n",
       "      <td>85</td>\n",
       "      <td>91</td>\n",
       "      <td>89</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bob</td>\n",
       "      <td>78</td>\n",
       "      <td>82</td>\n",
       "      <td>76</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>92</td>\n",
       "      <td>84</td>\n",
       "      <td>94</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Diana</td>\n",
       "      <td>88</td>\n",
       "      <td>89</td>\n",
       "      <td>92</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eve</td>\n",
       "      <td>76</td>\n",
       "      <td>90</td>\n",
       "      <td>88</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Math  English  Science Grade\n",
       "0    Alice    85       91       89     A\n",
       "1      Bob    78       82       76     B\n",
       "2  Charlie    92       84       94     A\n",
       "3    Diana    88       89       92     A\n",
       "4      Eve    76       90       88     B"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Name\": [\"Alice\", \"Bob\", \"Charlie\", \"Diana\", \"Eve\"],\n",
    "    \"Math\": [85, 78, 92, 88, 76],\n",
    "    \"English\": [91, 82, 84, 89, 90],\n",
    "    \"Science\": [89, 76, 94, 92, 88],\n",
    "    \"Grade\": [\"A\", \"B\", \"A\", \"A\", \"B\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "562dc4a9-fcb9-4f3c-8308-bd7277c98228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83.8"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the average score in Math across all students?\n",
    "df['Math'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2092cfcb-971f-4e63-b85e-d28996555dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which student has the highest score in Science?\n",
    "df['Science'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "39c09218-9bd2-4820-bdcd-2451185b2eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#How many students received a grade of 'A'?\n",
    "(df['Grade']== 'A').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8bebc917-ebe5-4559-b490-9bc40f64ba95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "436"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is the total English score of all students combined?\n",
    "df['English'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26659929-7412-4fc4-a00a-38b996d4b804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Which student has the lowest Math score?\n",
    "df['Math'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "63bc98ff-af16-434e-beb9-75c8678016a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#What is the average Science score of students with a grade of 'B'?\n",
    "df[df['Grade'] == 'B']['Science'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "726e300d-be89-4f2a-b357-2e15d8356f2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Experience_Years</th>\n",
       "      <th>Projects_Completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>HR</td>\n",
       "      <td>50000</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sara</td>\n",
       "      <td>IT</td>\n",
       "      <td>70000</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mike</td>\n",
       "      <td>IT</td>\n",
       "      <td>65000</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emma</td>\n",
       "      <td>Finance</td>\n",
       "      <td>72000</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liam</td>\n",
       "      <td>HR</td>\n",
       "      <td>48000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Employee Department  Salary  Experience_Years  Projects_Completed\n",
       "0     John         HR   50000                 5                  10\n",
       "1     Sara         IT   70000                 7                  15\n",
       "2     Mike         IT   65000                 4                  12\n",
       "3     Emma    Finance   72000                 8                  18\n",
       "4     Liam         HR   48000                 3                   7"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {\n",
    "    \"Employee\": [\"John\", \"Sara\", \"Mike\", \"Emma\", \"Liam\"],\n",
    "    \"Department\": [\"HR\", \"IT\", \"IT\", \"Finance\", \"HR\"],\n",
    "    \"Salary\": [50000, 70000, 65000, 72000, 48000],\n",
    "    \"Experience_Years\": [5, 7, 4, 8, 3],\n",
    "    \"Projects_Completed\": [10, 15, 12, 18, 7]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b71ba4f3-f2cc-48b4-8e41-77bd29d33171",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n1. What is the average salary of employees across all departments?\\n2. Which department has the employee with the highest number of projects completed?\\n3. How many employees have more than 5 years of experience?\\n4. What is the total salary of all employees in the IT department?\\n5. Which employee has the least number of projects completed?\\n6. What is the average experience of employees in the HR department?'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "1. What is the average salary of employees across all departments?\n",
    "2. Which department has the employee with the highest number of projects completed?\n",
    "3. How many employees have more than 5 years of experience?\n",
    "4. What is the total salary of all employees in the IT department?\n",
    "5. Which employee has the least number of projects completed?\n",
    "6. What is the average experience of employees in the HR department?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bcc0af3b-f7dc-4857-8331-6d4880bb6c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61000.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. What is the average salary of employees across all departments?\n",
    "df['Salary'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0901f3a3-f6db-4d8b-8f54-273751cbabe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Department\n",
       "Finance    72000.0\n",
       "HR         49000.0\n",
       "IT         67500.0\n",
       "Name: Salary, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('Department')['Salary'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2eaa1f38-5927-48d8-a71d-b21ad45abe71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Finance'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Which department has the employee with the highest number of projects completed?\n",
    "\n",
    "# Find the maximum number of projects completed\n",
    "max_projects = df['Projects_Completed'].max()\n",
    "\n",
    "# Find the department corresponding to the maximum projects completed\n",
    "department_with_max_proj = df[df['Projects_Completed']== max_projects]['Department'].iloc[0]\n",
    "\n",
    "department_with_max_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6f75c528-7a71-4dab-b3a9-397e564a4ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Employee</th>\n",
       "      <th>Department</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Experience_Years</th>\n",
       "      <th>Projects_Completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>John</td>\n",
       "      <td>HR</td>\n",
       "      <td>50000</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sara</td>\n",
       "      <td>IT</td>\n",
       "      <td>70000</td>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mike</td>\n",
       "      <td>IT</td>\n",
       "      <td>65000</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emma</td>\n",
       "      <td>Finance</td>\n",
       "      <td>72000</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Liam</td>\n",
       "      <td>HR</td>\n",
       "      <td>48000</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Employee Department  Salary  Experience_Years  Projects_Completed\n",
       "0     John         HR   50000                 5                  10\n",
       "1     Sara         IT   70000                 7                  15\n",
       "2     Mike         IT   65000                 4                  12\n",
       "3     Emma    Finance   72000                 8                  18\n",
       "4     Liam         HR   48000                 3                   7"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c5e8ea18-1d0a-487a-9bed-3fc07541b932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. How many employees have more than 5 years of experience?\n",
    "df[df['Experience_Years']>5].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9cc9eae0-8817-4bdd-b80f-04f9ff1948e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. What is the total salary of all employees in the IT department?\n",
    "df[df['Department']=='IT']['Salary'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0a4136b1-550d-489d-9406-b2749055c12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Liam'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. Which employee has the least number of projects completed?\n",
    "least_num_proj = df['Projects_Completed'].min()\n",
    "least_proj_employee = df[df['Projects_Completed']== least_num_proj]['Employee'].iloc[0]\n",
    "least_proj_employee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbd389a-abcc-4da5-b46e-ee71f6e47c81",
   "metadata": {},
   "source": [
    "# Evaluation Metrics by Problem Type:\n",
    "\n",
    "1. Classification Metrics\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "- Confusion Matrix\n",
    "- ROC Curve\n",
    "- AUC (Area Under Curve)\n",
    "- Cohen's Kappa\n",
    "- Log Loss\n",
    "- Precision-Recall Curve\n",
    "\n",
    "2. Regression Metrics\n",
    "- Mean Squared Error (MSE)\n",
    "- Root Mean Squared Error (RMSE)\n",
    "- Mean Absolute Error (MAE)\n",
    "- R-squared (RÂ²)\n",
    "- Adjusted R-squared\n",
    "- Mean Absolute Percentage Error (MAPE)\n",
    "\n",
    "3. Clustering Metrics\n",
    "- Silhouette Score\n",
    "- Davies-Bouldin Index\n",
    "- Calinski-Harabasz Index\n",
    "- Adjusted Rand Index\n",
    "- Mutual Information\n",
    "\n",
    "4. Ranking Metrics\n",
    "- Mean Average Precision\n",
    "- Normalized Discounted Cumulative Gain\n",
    "- Precision at K\n",
    "- Mean Reciprocal Rank\n",
    "\n",
    "5. Probabilistic Metrics\n",
    "- Likelihood\n",
    "- Log-likelihood\n",
    "- Kullback-Leibler Divergence\n",
    "- Brier Score\n",
    "\n",
    "6. Advanced Metrics\n",
    "- Information Gain\n",
    "- Entropy\n",
    "- Cross-entropy\n",
    "- Gini Impurity\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8425c8bb-63e3-4144-b15b-a47f8ddca341",
   "metadata": {},
   "source": [
    "# Choosing the Right Evaluation Metric:\n",
    "\n",
    "1. Classification Problems\n",
    "- Accuracy: Balanced classes, equal importance\n",
    "- Precision: Important when false positives are costly\n",
    "- Recall: Critical when false negatives are dangerous\n",
    "- F1 Score: Balance between precision and recall\n",
    "- ROC AUC: Model's discrimination ability\n",
    "- Log Loss: Probabilistic predictions\n",
    "\n",
    "2. Use Case Examples\n",
    "- Fraud Detection\n",
    "  * High Recall (catch all frauds)\n",
    "  * Low False Negative Rate\n",
    "  * Precision less critical\n",
    "\n",
    "- Spam Filtering\n",
    "  * Precision important\n",
    "  * Minimize false positives\n",
    "  * Some missed spam acceptable\n",
    "\n",
    "- Medical Diagnosis\n",
    "  * High Recall crucial\n",
    "  * Missing a disease worse than false alarm\n",
    "  * F1 Score or Sensitivity key\n",
    "\n",
    "3. Regression Problems\n",
    "- MSE: Sensitive to outliers\n",
    "- RMSE: More interpretable, same units as target\n",
    "- MAE: Less sensitive to outliers\n",
    "- R-squared: Overall model fit\n",
    "\n",
    "4. Imbalanced Datasets\n",
    "- Precision-Recall Curve\n",
    "- Cohen's Kappa\n",
    "- Matthews Correlation Coefficient\n",
    "- Balanced Accuracy\n",
    "\n",
    "5. Decision Factors\n",
    "- Business impact\n",
    "- Cost of errors\n",
    "- Data distribution\n",
    "- Problem complexity\n",
    "- Model type\n",
    "\n",
    "6. Domain-Specific Considerations\n",
    "- Finance: Minimize risk\n",
    "- Healthcare: Maximize detection\n",
    "- Marketing: Predict conversion\n",
    "- Manufacturing: Minimize defects\n",
    "\n",
    "Key Principles:\n",
    "- Understand problem context\n",
    "- Consider error costs\n",
    "- Match metric to goal\n",
    "- Use multiple metrics\n",
    "- Validate across scenarios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be708c-ee64-4a2e-9f53-80c12e04913c",
   "metadata": {},
   "source": [
    "#  Pivot Table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fbb308-7ae9-4c6b-a51c-24182c97c904",
   "metadata": {},
   "source": [
    "Pivot tables are used for:\n",
    "\n",
    "1. Data Summarization: Quickly condensing large datasets by aggregating and organizing information across different dimensions.\n",
    "\n",
    "2. Statistical Analysis: Enabling rapid calculation of totals, averages, counts, and other statistical measures across multiple categories.\n",
    "\n",
    "3. Data Visualization: Transforming complex raw data into easily readable and interpretable formats.\n",
    "\n",
    "4. Comparative Analysis: Allowing users to compare data across different groups, time periods, or categories with minimal manual manipulation.\n",
    "\n",
    "5. Dynamic Reporting: Providing flexible tools for business intelligence, financial analysis, and performance tracking by allowing real-time data reorganization and summarization.\n",
    "\n",
    "Example applications include sales reporting, inventory management, financial analysis, and customer behavior research."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bfdb328d-68a1-4dbe-b267-d33fc3dc6b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/1/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>66</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/3/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>68</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/1/2017</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date      city  temperature  humidity\n",
       "0  5/1/2017  new york           65        56\n",
       "1  5/2/2017  new york           66        58\n",
       "2  5/3/2017  new york           68        60\n",
       "3  5/1/2017    mumbai           75        80\n",
       "4  5/2/2017    mumbai           78        83"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/aromal/Documents/All_Weeks/Week_13/Datasets/weather.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "dbb61e4f-0871-4e13-83f6-3b9b7c676787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">temperature</th>\n",
       "      <th colspan=\"3\" halign=\"left\">humidity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>beijing</th>\n",
       "      <th>mumbai</th>\n",
       "      <th>new york</th>\n",
       "      <th>beijing</th>\n",
       "      <th>mumbai</th>\n",
       "      <th>new york</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5/1/2017</th>\n",
       "      <td>80</td>\n",
       "      <td>75</td>\n",
       "      <td>65</td>\n",
       "      <td>26</td>\n",
       "      <td>80</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/2/2017</th>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "      <td>66</td>\n",
       "      <td>30</td>\n",
       "      <td>83</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/3/2017</th>\n",
       "      <td>79</td>\n",
       "      <td>82</td>\n",
       "      <td>68</td>\n",
       "      <td>35</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         temperature                 humidity                \n",
       "city         beijing mumbai new york  beijing mumbai new york\n",
       "date                                                         \n",
       "5/1/2017          80     75       65       26     80       56\n",
       "5/2/2017          77     78       66       30     83       58\n",
       "5/3/2017          79     82       68       35     85       60"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot(index='date', columns='city', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7859ecfb-dd82-426b-bcd0-67a56cc0f925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>city</th>\n",
       "      <th>beijing</th>\n",
       "      <th>mumbai</th>\n",
       "      <th>new york</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5/1/2017</th>\n",
       "      <td>26</td>\n",
       "      <td>80</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/2/2017</th>\n",
       "      <td>30</td>\n",
       "      <td>83</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/3/2017</th>\n",
       "      <td>35</td>\n",
       "      <td>85</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "city      beijing  mumbai  new york\n",
       "date                               \n",
       "5/1/2017       26      80        56\n",
       "5/2/2017       30      83        58\n",
       "5/3/2017       35      85        60"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.pivot(index='date', columns='city', data=df, values='humidity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d170d596-2cfc-4416-a79d-9eacc67ab005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/1/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/1/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>61</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5/1/2017</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5/1/2017</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>78</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>82</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>mumbai</td>\n",
       "      <td>80</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       date      city  temperature  humidity\n",
       "0  5/1/2017  new york           65        56\n",
       "1  5/1/2017  new york           61        54\n",
       "2  5/2/2017  new york           70        60\n",
       "3  5/2/2017  new york           72        62\n",
       "4  5/1/2017    mumbai           75        80\n",
       "5  5/1/2017    mumbai           78        83\n",
       "6  5/2/2017    mumbai           82        85\n",
       "7  5/2/2017    mumbai           80        26"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/aromal/Documents/All_Weeks/Week_13/Datasets/weather2.csv')\n",
    "df\n",
    "# have both morning and evening tempratures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "470e2af8-58e5-49e3-8c31-d9c20ddfc9b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">humidity</th>\n",
       "      <th colspan=\"2\" halign=\"left\">temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>5/1/2017</th>\n",
       "      <th>5/2/2017</th>\n",
       "      <th>5/1/2017</th>\n",
       "      <th>5/2/2017</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mumbai</th>\n",
       "      <td>81.5</td>\n",
       "      <td>55.5</td>\n",
       "      <td>76.5</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>55.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         humidity          temperature         \n",
       "date     5/1/2017 5/2/2017    5/1/2017 5/2/2017\n",
       "city                                           \n",
       "mumbai       81.5     55.5        76.5     81.0\n",
       "new york     55.0     61.0        63.0     71.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index='city', columns='date')\n",
    "# average temprature is shown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d93fd85b-10e3-4df3-a4b1-43ca474b2e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">humidity</th>\n",
       "      <th colspan=\"2\" halign=\"left\">temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>5/1/2017</th>\n",
       "      <th>5/2/2017</th>\n",
       "      <th>5/1/2017</th>\n",
       "      <th>5/2/2017</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mumbai</th>\n",
       "      <td>163</td>\n",
       "      <td>111</td>\n",
       "      <td>153</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>110</td>\n",
       "      <td>122</td>\n",
       "      <td>126</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         humidity          temperature         \n",
       "date     5/1/2017 5/2/2017    5/1/2017 5/2/2017\n",
       "city                                           \n",
       "mumbai        163      111         153      162\n",
       "new york      110      122         126      142"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index='city', columns='date', aggfunc='sum')\n",
    "# or use aggregate function\n",
    "# mean is default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "65a2a96a-bae5-4aa9-88e3-61fcf5fd6200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">humidity</th>\n",
       "      <th colspan=\"3\" halign=\"left\">temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th>5/1/2017</th>\n",
       "      <th>5/2/2017</th>\n",
       "      <th>All</th>\n",
       "      <th>5/1/2017</th>\n",
       "      <th>5/2/2017</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mumbai</th>\n",
       "      <td>81.50</td>\n",
       "      <td>55.50</td>\n",
       "      <td>68.50</td>\n",
       "      <td>76.50</td>\n",
       "      <td>81.0</td>\n",
       "      <td>78.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new york</th>\n",
       "      <td>55.00</td>\n",
       "      <td>61.00</td>\n",
       "      <td>58.00</td>\n",
       "      <td>63.00</td>\n",
       "      <td>71.0</td>\n",
       "      <td>67.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>68.25</td>\n",
       "      <td>58.25</td>\n",
       "      <td>63.25</td>\n",
       "      <td>69.75</td>\n",
       "      <td>76.0</td>\n",
       "      <td>72.875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         humidity                 temperature                 \n",
       "date     5/1/2017 5/2/2017    All    5/1/2017 5/2/2017     All\n",
       "city                                                          \n",
       "mumbai      81.50    55.50  68.50       76.50     81.0  78.750\n",
       "new york    55.00    61.00  58.00       63.00     71.0  67.000\n",
       "All         68.25    58.25  63.25       69.75     76.0  72.875"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index='city', columns='date', margins=True)\n",
    "# even shows the average of the two averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ab4c1dd2-b8c1-44d1-907c-2b480bdf6551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/1/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/2/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>61</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5/3/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/1/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/2/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>28</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12/3/2017</td>\n",
       "      <td>new york</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      city  temperature  humidity\n",
       "0   5/1/2017  new york           65        56\n",
       "1   5/2/2017  new york           61        54\n",
       "2   5/3/2017  new york           70        60\n",
       "3  12/1/2017  new york           30        50\n",
       "4  12/2/2017  new york           28        52\n",
       "5  12/3/2017  new york           25        51"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/home/aromal/Documents/All_Weeks/Week_13/Datasets/weather3.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "36cad756-f684-407a-b50c-a75284574df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>city</th>\n",
       "      <th>temperature</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>new york</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>new york</td>\n",
       "      <td>61</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-03</td>\n",
       "      <td>new york</td>\n",
       "      <td>70</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-12-01</td>\n",
       "      <td>new york</td>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-12-02</td>\n",
       "      <td>new york</td>\n",
       "      <td>28</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2017-12-03</td>\n",
       "      <td>new york</td>\n",
       "      <td>25</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date      city  temperature  humidity\n",
       "0 2017-05-01  new york           65        56\n",
       "1 2017-05-02  new york           61        54\n",
       "2 2017-05-03  new york           70        60\n",
       "3 2017-12-01  new york           30        50\n",
       "4 2017-12-02  new york           28        52\n",
       "5 2017-12-03  new york           25        51"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "db1c9554-a59e-4e91-a45c-d37a0d792511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17970/1797274567.py:1: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  df.pivot_table(index=pd.Grouper(freq='M', key='date'), columns='city')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>humidity</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <th>new york</th>\n",
       "      <th>new york</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-05-31</th>\n",
       "      <td>56.666667</td>\n",
       "      <td>65.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>27.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             humidity temperature\n",
       "city         new york    new york\n",
       "date                             \n",
       "2017-05-31  56.666667   65.333333\n",
       "2017-12-31  51.000000   27.666667"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pivot_table(index=pd.Grouper(freq='M', key='date'), columns='city')\n",
    "#average temprature in each month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640ddaae-af9a-4830-b19e-d7a0e9ce66a0",
   "metadata": {},
   "source": [
    "# Linear Algebra\n",
    "\n",
    "1. What is an eigenvector and why is it important in machine learning?\n",
    "   - Answer: An eigenvector is a vector that, when a linear transformation is applied, changes only in magnitude but not in direction. In machine learning, eigenvectors are crucial for:\n",
    "     * Principal Component Analysis (PCA)\n",
    "     * Dimensionality reduction\n",
    "     * Understanding data variance\n",
    "     * Analyzing neural network weight matrices\n",
    "\n",
    "2. Explain the concept of matrix rank in machine learning context.\n",
    "   - Answer: Matrix rank represents the number of linearly independent rows or columns in a matrix. In machine learning, rank is important for:\n",
    "     * Determining feature independence\n",
    "     * Identifying linear dependencies\n",
    "     * Resolving overfitting\n",
    "     * Assessing the complexity of learning algorithms\n",
    "\n",
    "3. What is the significance of the dot product in machine learning?\n",
    "   - Answer: The dot product measures similarity between vectors and is fundamental in:\n",
    "     * Calculating cosine similarity\n",
    "     * Neural network computations\n",
    "     * Feature vector comparisons\n",
    "     * Implementing inner product operations in algorithms\n",
    "\n",
    "4. How do linear transformations relate to machine learning algorithms?\n",
    "   - Answer: Linear transformations help:\n",
    "     * Reshape data spaces\n",
    "     * Rotate and scale feature vectors\n",
    "     * Implement linear regression\n",
    "     * Perform coordinate system transformations\n",
    "     * Represent neural network layer operations\n",
    "\n",
    "5. What is the purpose of singular value decomposition (SVD) in machine learning?\n",
    "   - Answer: SVD decomposes a matrix into three matrices (U, Î£, V^T), crucial for:\n",
    "     * Dimensionality reduction\n",
    "     * Recommender systems\n",
    "     * Data compression\n",
    "     * Noise reduction in data\n",
    "     * Feature extraction\n",
    "\n",
    "6. Explain the importance of matrix inverse in machine learning algorithms.\n",
    "   - Answer: Matrix inverse helps in:\n",
    "     * Solving linear regression equations\n",
    "     * Computing parameter estimates\n",
    "     * Implementing gradient descent\n",
    "     * Transforming coordinate systems\n",
    "     * Calculating least squares solutions\n",
    "\n",
    "7. What is the role of orthogonal matrices in machine learning?\n",
    "   - Answer: Orthogonal matrices:\n",
    "     * Preserve vector lengths and angles\n",
    "     * Used in rotation and reflection transformations\n",
    "     * Maintain data structure during transformations\n",
    "     * Essential in PCA and data normalization\n",
    "     * Ensure computational stability\n",
    "\n",
    "8. How do determinants relate to machine learning?\n",
    "   - Answer: Determinants help:\n",
    "     * Measure linear transformation scaling\n",
    "     * Detect matrix singularity\n",
    "     * Assess linear independence\n",
    "     * Compute volume transformations\n",
    "     * Indicate matrix invertibility\n",
    "\n",
    "9. What is the significance of the Gram matrix in machine learning?\n",
    "   - Answer: Gram matrix represents inner products between vectors, used in:\n",
    "     * Kernel methods\n",
    "     * Support Vector Machines\n",
    "     * Feature space transformations\n",
    "     * Measuring vector similarities\n",
    "     * Computing kernel tricks\n",
    "\n",
    "10. Explain the concept of vector projection in machine learning context.\n",
    "    - Answer: Vector projection helps:\n",
    "      * Decompose vectors into components\n",
    "      * Compute feature importance\n",
    "      * Reduce dimensionality\n",
    "      * Understand data alignments\n",
    "      * Implement linear regression techniques\n",
    "\n",
    "11. What is the role of matrix condition number in machine learning?\n",
    "    - Answer: Condition number indicates:\n",
    "      * Numerical stability of algorithms\n",
    "      * Sensitivity to input perturbations\n",
    "      * Matrix invertibility challenges\n",
    "      * Computational complexity\n",
    "      * Potential for numerical instability\n",
    "\n",
    "12. How do eigenvalues contribute to machine learning algorithms?\n",
    "    - Answer: Eigenvalues help:\n",
    "      * Measure data variance\n",
    "      * Identify principal components\n",
    "      * Analyze network stability\n",
    "      * Determine matrix transformations\n",
    "      * Understand feature importance\n",
    "\n",
    "13. What is the significance of the null space in machine learning?\n",
    "    - Answer: Null space helps:\n",
    "      * Identify linearly dependent features\n",
    "      * Understand model constraints\n",
    "      * Detect feature redundancy\n",
    "      * Analyze linear transformations\n",
    "      * Solve underdetermined systems\n",
    "\n",
    "14. Explain the concept of matrix pseudoinverse in ML algorithms.\n",
    "    - Answer: Pseudoinverse (Moore-Penrose inverse):\n",
    "      * Solves linear least squares problems\n",
    "      * Handles non-square matrices\n",
    "      * Computes generalized inverse\n",
    "      * Used in regression techniques\n",
    "      * Provides minimum norm solutions\n",
    "\n",
    "15. How do tensor operations relate to machine learning?\n",
    "    - Answer: Tensor operations:\n",
    "      * Handle multi-dimensional data\n",
    "      * Crucial in deep learning\n",
    "      * Represent complex transformations\n",
    "      * Enable advanced neural network architectures\n",
    "      * Support parallel computations\n",
    "\n",
    "16. What is the role of matrix trace in machine learning?\n",
    "    - Answer: Matrix trace:\n",
    "      * Measures matrix invariants\n",
    "      * Calculates total variance\n",
    "      * Used in dimensionality reduction\n",
    "      * Helps in optimization algorithms\n",
    "      * Provides computational shortcuts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b61c5-dabc-45ac-8d2c-27bb09da85c5",
   "metadata": {},
   "source": [
    "# Linear Algebra for Machine Learning: Questions and Answers\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Vectors and Matrix Operations**\n",
    "### **Q1: What is the dot product of two vectors, and how is it computed?**\n",
    "\n",
    "**Answer:**\n",
    "The **dot product** of two vectors \\( \\mathbf{u} = [u_1, u_2, ..., u_n] \\) and \\( \\mathbf{v} = [v_1, v_2, ..., v_n] \\) is computed as:\n",
    "\n",
    "\\[\n",
    "\\mathbf{u} \\cdot \\mathbf{v} = u_1 v_1 + u_2 v_2 + \\cdots + u_n v_n\n",
    "\\]\n",
    "\n",
    "Example:  \n",
    "For \\( \\mathbf{u} = [1, 2] \\) and \\( \\mathbf{v} = [3, 4] \\):\n",
    "\n",
    "\\[\n",
    "\\mathbf{u} \\cdot \\mathbf{v} = (1 \\cdot 3) + (2 \\cdot 4) = 3 + 8 = 11\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Matrix Multiplication**\n",
    "### **Q2: How do you multiply two matrices? Compute the product of the matrices:**\n",
    "\n",
    "\\[\n",
    "\\mathbf{A} = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}, \\quad \\mathbf{B} = \\begin{bmatrix} 2 & 0 \\\\ 1 & 2 \\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "**Answer:**\n",
    "Matrix multiplication is done by taking the dot product of the rows of the first matrix with the columns of the second matrix.\n",
    "\n",
    "\\[\n",
    "\\mathbf{A} \\cdot \\mathbf{B} = \n",
    "\\begin{bmatrix} \n",
    "(1 \\cdot 2 + 2 \\cdot 1) & (1 \\cdot 0 + 2 \\cdot 2) \\\\ \n",
    "(3 \\cdot 2 + 4 \\cdot 1) & (3 \\cdot 0 + 4 \\cdot 2) \n",
    "\\end{bmatrix}\n",
    "= \n",
    "\\begin{bmatrix} \n",
    "4 & 4 \\\\ \n",
    "10 & 8 \n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Eigenvalues and Eigenvectors**\n",
    "### **Q3: What is an eigenvalue and eigenvector? How are they used in machine learning?**\n",
    "\n",
    "**Answer:**\n",
    "An **eigenvector** of a square matrix \\( \\mathbf{A} \\) is a non-zero vector \\( \\mathbf{v} \\) that satisfies the equation:\n",
    "\n",
    "\\[\n",
    "\\mathbf{A} \\mathbf{v} = \\lambda \\mathbf{v}\n",
    "\\]\n",
    "\n",
    "where \\( \\lambda \\) is the **eigenvalue** associated with the eigenvector \\( \\mathbf{v} \\).\n",
    "\n",
    "In machine learning, eigenvectors and eigenvalues are crucial for:\n",
    "- **Principal Component Analysis (PCA)**, which reduces the dimensionality of large datasets.\n",
    "- **Understanding data transformations** in various algorithms, such as in deep learning and recommendation systems.\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Singular Value Decomposition (SVD)**\n",
    "### **Q4: What is the Singular Value Decomposition (SVD) of a matrix?**\n",
    "\n",
    "**Answer:**\n",
    "Singular Value Decomposition (SVD) decomposes a matrix \\( \\mathbf{A} \\) into three matrices:\n",
    "\n",
    "\\[\n",
    "\\mathbf{A} = \\mathbf{U} \\Sigma \\mathbf{V}^T\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( \\mathbf{U} \\) is a matrix of left singular vectors.\n",
    "- \\( \\Sigma \\) is a diagonal matrix with singular values.\n",
    "- \\( \\mathbf{V}^T \\) is a matrix of right singular vectors.\n",
    "\n",
    "In machine learning, SVD is used in:\n",
    "- **Dimensionality reduction** (e.g., in PCA).\n",
    "- **Data compression** and **recommendation systems**.\n",
    "\n",
    "\n",
    "Hereâ€™s what each matrix represents:\n",
    "- **\\( \\mathbf{U} \\)**: A matrix containing the **left singular vectors**. Its columns are orthonormal, meaning \\( \\mathbf{U}^T \\mathbf{U} = \\mathbf{I} \\).\n",
    "- **\\( \\Sigma \\)**: A diagonal matrix containing the **singular values** (non-negative real numbers) of \\( \\mathbf{A} \\), sorted in decreasing order.\n",
    "- **\\( \\mathbf{V}^T \\)**: A matrix containing the **right singular vectors**, also orthonormal.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3ec69984-85b6-4d9f-82b5-67e1a9a05b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U:\n",
      " [[-0.70710678 -0.70710678  0.        ]\n",
      " [-0.70710678  0.70710678  0.        ]\n",
      " [ 0.          0.          1.        ]]\n",
      "Singular Values (S):\n",
      " [5. 1.]\n",
      "V^T:\n",
      " [[-0.70710678 -0.70710678]\n",
      " [-0.70710678  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "# Example matrix\n",
    "A = np.array([[3, 2], [2, 3], [0, 0]])\n",
    "\n",
    "# Perform SVD\n",
    "U, S, VT = np.linalg.svd(A)\n",
    "\n",
    "print(\"U:\\n\", U)\n",
    "print(\"Singular Values (S):\\n\", S)\n",
    "print(\"V^T:\\n\", VT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea181ce4-75df-44e5-9295-edd65f846411",
   "metadata": {},
   "source": [
    "## **5. Vector Spaces and Linear Independence**\n",
    "### **Q5: What is the rank of a matrix, and how does it relate to linear independence?**\n",
    "\n",
    "**Answer:**\n",
    "The **rank** of a matrix is the number of linearly independent rows or columns. It tells you how many dimensions the matrix spans.\n",
    "\n",
    "- If the matrix has full rank (i.e., the rank equals the number of rows or columns), all rows/columns are linearly independent.\n",
    "- The rank is important in machine learning, especially in methods like **linear regression** or **PCA**, where the rank helps determine if a solution is unique and if the data has redundancy.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Norms and Distance Metrics**\n",
    "### **Q6: Compute the \\( L_2 \\)-norm of the vector \\( \\mathbf{v} = [3, 4] \\).**\n",
    "\n",
    "**Answer:**\n",
    "The \\( L_2 \\)-norm (Euclidean norm) is given by:\n",
    "\n",
    "\\[\n",
    "\\| \\mathbf{v} \\|_2 = \\sqrt{3^2 + 4^2} = \\sqrt{9 + 16} = 5\n",
    "\\]\n",
    "\n",
    "The \\( L_2 \\)-norm is often used in machine learning to measure the magnitude of vectors, particularly in gradient-based optimization algorithms.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Matrix Inversion**\n",
    "### **Q7: How do you compute the inverse of a 2x2 matrix?**\n",
    "\n",
    "**Answer:**\n",
    "The inverse of a 2x2 matrix:\n",
    "\n",
    "\\[\n",
    "\\mathbf{A} = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "is given by:\n",
    "\n",
    "\\[\n",
    "\\mathbf{A}^{-1} = \\frac{1}{ad - bc} \\begin{bmatrix} d & -b \\\\ -c & a \\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "**Note:** The inverse exists only if the determinant \\( ad - bc \\neq 0 \\).\n",
    "\n",
    "In machine learning, matrix inversion is used in solving systems of linear equations, particularly in **linear regression**.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Principal Component Analysis (PCA)**\n",
    "### **Q8: How is PCA used in machine learning, and what role does linear algebra play in it?**\n",
    "\n",
    "**Answer:**\n",
    "Principal Component Analysis (PCA) is used to reduce the dimensionality of data by projecting it onto a set of orthogonal axes (principal components) that capture the most variance in the data.\n",
    "\n",
    "- PCA involves finding the eigenvectors and eigenvalues of the covariance matrix of the data. The eigenvectors form the new axes, and the eigenvalues determine the importance of each axis.\n",
    "- Linear algebra, particularly eigenvectors and eigenvalues, plays a key role in PCA as it enables the transformation of high-dimensional data into a lower-dimensional space while preserving most of the data's variance.\n",
    "\n",
    "\n",
    "## **9. Linear Transformations**\n",
    "### **Q1: What is a linear transformation, and how does it relate to matrices?**\n",
    "\n",
    "**Answer:**\n",
    "A **linear transformation** is a function \\( T: \\mathbb{R}^n \\to \\mathbb{R}^m \\) that satisfies two properties:\n",
    "1. **Additivity**: \\( T(\\mathbf{u} + \\mathbf{v}) = T(\\mathbf{u}) + T(\\mathbf{v}) \\)\n",
    "2. **Homogeneity**: \\( T(c \\mathbf{v}) = c T(\\mathbf{v}) \\)\n",
    "\n",
    "Linear transformations can be represented by matrices. If \\( T \\) is a linear transformation, then for any vector \\( \\mathbf{v} \\in \\mathbb{R}^n \\), the transformation is given by:\n",
    "\n",
    "\\[\n",
    "T(\\mathbf{v}) = \\mathbf{A} \\mathbf{v}\n",
    "\\]\n",
    "\n",
    "where \\( \\mathbf{A} \\) is the matrix representing the linear transformation.\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Determinant**\n",
    "### **Q2: What is the determinant of a matrix, and what does it signify?**\n",
    "\n",
    "**Answer:**\n",
    "The **determinant** of a square matrix \\( \\mathbf{A} \\) is a scalar value that provides important information about the matrix, such as whether it is invertible. For a 2x2 matrix:\n",
    "\n",
    "\\[\n",
    "\\mathbf{A} = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "the determinant is given by:\n",
    "\n",
    "\\[\n",
    "\\text{det}(\\mathbf{A}) = ad - bc\n",
    "\\]\n",
    "\n",
    "If the determinant is non-zero, the matrix is invertible. If the determinant is zero, the matrix is singular and does not have an inverse.\n",
    "\n",
    "In machine learning, the determinant can be used to determine the properties of transformation matrices in methods such as **linear regression** or **PCA**.\n",
    "\n",
    "---\n",
    "\n",
    "## **11. Orthogonality**\n",
    "### **Q3: What does it mean for two vectors to be orthogonal? How is this useful in machine learning?**\n",
    "\n",
    "**Answer:**\n",
    "Two vectors \\( \\mathbf{u} \\) and \\( \\mathbf{v} \\) are **orthogonal** if their dot product is zero:\n",
    "\n",
    "\\[\n",
    "\\mathbf{u} \\cdot \\mathbf{v} = 0\n",
    "\\]\n",
    "\n",
    "In machine learning, orthogonality is important because it often means that the vectors (or features) are independent of each other. In methods like **Principal Component Analysis (PCA)**, the principal components are orthogonal to one another, which helps reduce redundancy and ensures that the components capture different aspects of the data's variability.\n",
    "\n",
    "---\n",
    "\n",
    "## **12. Gram-Schmidt Process**\n",
    "### **Q4: What is the Gram-Schmidt process, and how is it used in machine learning?**\n",
    "\n",
    "**Answer:**\n",
    "The **Gram-Schmidt process** is an algorithm for orthonormalizing a set of vectors. Given a set of linearly independent vectors, it generates an orthogonal set of vectors that span the same subspace.\n",
    "\n",
    "The process is applied iteratively to each vector in the set, subtracting out the components in the direction of previously orthonormalized vectors.\n",
    "\n",
    "In machine learning, the Gram-Schmidt process is used in **QR decomposition** and **orthogonalization** methods to ensure numerical stability in algorithms like **linear regression** and **principal component analysis (PCA)**.\n",
    "\n",
    "---\n",
    "\n",
    "## **13. Diagonalization**\n",
    "### **Q5: What is diagonalization, and how does it relate to eigenvalues and eigenvectors?**\n",
    "\n",
    "**Answer:**\n",
    "A matrix \\( \\mathbf{A} \\) is **diagonalizable** if it can be written as:\n",
    "\n",
    "\\[\n",
    "\\mathbf{A} = \\mathbf{P} \\mathbf{D} \\mathbf{P}^{-1}\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( \\mathbf{P} \\) is a matrix whose columns are the eigenvectors of \\( \\mathbf{A} \\),\n",
    "- \\( \\mathbf{D} \\) is a diagonal matrix with the corresponding eigenvalues of \\( \\mathbf{A} \\).\n",
    "\n",
    "Diagonalization simplifies many matrix operations, as powers of diagonal matrices are easy to compute. In machine learning, diagonalization is used in **eigenvalue decomposition** in techniques like **PCA**, where the eigenvectors (principal components) are orthogonal, and the diagonal matrix contains the variance of each component.\n",
    "\n",
    "---\n",
    "\n",
    "## **14. Condition Number**\n",
    "### **Q6: What is the condition number of a matrix, and why is it important in machine learning?**\n",
    "\n",
    "**Answer:**\n",
    "The **condition number** of a matrix \\( \\mathbf{A} \\), denoted \\( \\kappa(\\mathbf{A}) \\), measures how sensitive the solution of a system of linear equations is to changes in the input. It is computed as the ratio of the largest singular value to the smallest singular value:\n",
    "\n",
    "\\[\n",
    "\\kappa(\\mathbf{A}) = \\frac{\\sigma_{\\text{max}}}{\\sigma_{\\text{min}}}\n",
    "\\]\n",
    "\n",
    "A large condition number indicates that the matrix is **ill-conditioned**, meaning that small changes in input can lead to large changes in the solution. In machine learning, ill-conditioning can cause **numerical instability** in algorithms like **linear regression** and **SVD**.\n",
    "\n",
    "---\n",
    "\n",
    "## **15. Least Squares Solution**\n",
    "### **Q7: How is the least squares solution of a system of linear equations found, and why is it used in machine learning?**\n",
    "\n",
    "**Answer:**\n",
    "For an overdetermined system of linear equations \\( \\mathbf{A} \\mathbf{x} = \\mathbf{b} \\), the least squares solution minimizes the residual sum of squares:\n",
    "\n",
    "\\[\n",
    "\\hat{\\mathbf{x}} = \\arg\\min_{\\mathbf{x}} \\| \\mathbf{A} \\mathbf{x} - \\mathbf{b} \\|^2\n",
    "\\]\n",
    "\n",
    "The solution is given by:\n",
    "\n",
    "\\[\n",
    "\\hat{\\mathbf{x}} = (\\mathbf{A}^T \\mathbf{A})^{-1} \\mathbf{A}^T \\mathbf{b}\n",
    "\\]\n",
    "\n",
    "In machine learning, the least squares method is commonly used to find the best fit in **linear regression**, where the goal is to minimize the difference between the predicted values and the actual data points.\n",
    "\n",
    "---\n",
    "\n",
    "## **16. Covariance Matrix**\n",
    "### **Q8: What is the covariance matrix, and how is it used in machine learning?**\n",
    "\n",
    "**Answer:**\n",
    "The **covariance matrix** is a square matrix that contains the covariances between pairs of elements in a dataset. For a dataset with vectors \\( \\mathbf{x_1}, \\mathbf{x_2}, ..., \\mathbf{x_n} \\), the covariance matrix is given by:\n",
    "\n",
    "\\[\n",
    "\\mathbf{C} = \\frac{1}{n-1} \\sum_{i=1}^n (\\mathbf{x_i} - \\mu)(\\mathbf{x_i} - \\mu)^T\n",
    "\\]\n",
    "\n",
    "where \\( \\mu \\) is the mean vector.\n",
    "\n",
    "In machine learning, the covariance matrix is used in **PCA** to determine the directions of maximum variance in the data and is crucial in understanding relationships between features in a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3359bb0e-9341-4a55-9384-dd6ea32d1e05",
   "metadata": {},
   "source": [
    "# Statistics and Probability for Machine Learning: Questions and Answers\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Descriptive Statistics**\n",
    "### **Q1: What is the difference between mean, median, and mode?**\n",
    "\n",
    "**Answer:**\n",
    "- **Mean**: The average of a set of numbers, calculated as the sum of the numbers divided by the count.  \n",
    "  \\[\n",
    "  \\text{Mean} = \\frac{1}{n} \\sum_{i=1}^{n} x_i\n",
    "  \\]\n",
    "  \n",
    "- **Median**: The middle value when the data is sorted. If the number of data points is odd, the median is the middle number. If even, it is the average of the two middle numbers.\n",
    "  \n",
    "- **Mode**: The value that appears most frequently in a dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Variance and Standard Deviation**\n",
    "### **Q2: What is the variance and standard deviation of a dataset, and how are they related?**\n",
    "\n",
    "**Answer:**\n",
    "- **Variance**: A measure of the spread of data points around the mean. It is calculated as:\n",
    "  \\[\n",
    "  \\text{Variance} = \\frac{1}{n} \\sum_{i=1}^{n} (x_i - \\mu)^2\n",
    "  \\]\n",
    "  where \\( \\mu \\) is the mean.\n",
    "\n",
    "- **Standard Deviation**: The square root of the variance, providing a measure of spread in the same units as the data:\n",
    "  \\[\n",
    "  \\text{Standard Deviation} = \\sqrt{\\text{Variance}}\n",
    "  \\]\n",
    "\n",
    "The standard deviation gives a more interpretable measure of variability than variance, since it's in the same units as the data.\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Probability Theory**\n",
    "### **Q3: What is conditional probability?**\n",
    "\n",
    "**Answer:**\n",
    "**Conditional probability** is the probability of an event \\( A \\) occurring given that another event \\( B \\) has occurred. It is denoted as \\( P(A|B) \\) and is given by the formula:\n",
    "\n",
    "\\[\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( P(A \\cap B) \\) is the probability of both events \\( A \\) and \\( B \\) occurring,\n",
    "- \\( P(B) \\) is the probability of event \\( B \\).\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Bayes' Theorem**\n",
    "### **Q4: What is Bayes' Theorem and how is it used in machine learning?**\n",
    "\n",
    "**Answer:**\n",
    "**Bayes' Theorem** relates the conditional probabilities of two events, providing a way to update the probability of an event based on new evidence. The formula is:\n",
    "\n",
    "\\[\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( P(A|B) \\) is the posterior probability of event \\( A \\) given \\( B \\),\n",
    "- \\( P(B|A) \\) is the likelihood of observing \\( B \\) given \\( A \\),\n",
    "- \\( P(A) \\) is the prior probability of \\( A \\),\n",
    "- \\( P(B) \\) is the probability of \\( B \\).\n",
    "\n",
    "In machine learning, Bayes' Theorem is used in **Naive Bayes classification**, where we calculate the posterior probability of classes based on input features.\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Distributions**\n",
    "### **Q5: What is a normal distribution, and why is it important in machine learning?**\n",
    "\n",
    "**Answer:**\n",
    "A **normal distribution** (or Gaussian distribution) is a continuous probability distribution that is symmetric around the mean, with the majority of data points clustering near the mean. Its probability density function is given by:\n",
    "\n",
    "\\[\n",
    "f(x) = \\frac{1}{\\sqrt{2\\pi \\sigma^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( \\mu \\) is the mean,\n",
    "- \\( \\sigma \\) is the standard deviation.\n",
    "\n",
    "The normal distribution is important in machine learning because many algorithms (e.g., **Linear Regression**, **Logistic Regression**, **Bayesian methods**) assume that the errors or residuals follow a normal distribution.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Central Limit Theorem**\n",
    "### **Q6: What is the Central Limit Theorem (CLT)?**\n",
    "\n",
    "**Answer:**\n",
    "The **Central Limit Theorem** states that the distribution of the sample mean (or sum) approaches a normal distribution as the sample size increases, regardless of the original distribution of the data. This is critical in machine learning as it allows us to make inferences about the population mean even if the data is not normally distributed, as long as the sample size is large enough.\n",
    "\n",
    "---\n",
    "\n",
    "## **7. Hypothesis Testing**\n",
    "### **Q7: What is the null hypothesis in hypothesis testing?**\n",
    "\n",
    "**Answer:**\n",
    "The **null hypothesis** (denoted \\( H_0 \\)) is the hypothesis that there is no effect or no difference. It is the default assumption that any observed effect is due to random chance. For example, in a test of whether a new treatment is effective, the null hypothesis might state that the treatment has no effect.\n",
    "\n",
    "In hypothesis testing, we attempt to reject the null hypothesis by finding sufficient evidence (using p-values) that the observed data is inconsistent with it.\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Confidence Intervals**\n",
    "### **Q8: What is a confidence interval?**\n",
    "\n",
    "**Answer:**\n",
    "A **confidence interval** is a range of values, derived from the sample data, that is likely to contain the population parameter (such as the mean) with a certain level of confidence. A 95% confidence interval means that if the same sampling procedure were repeated many times, 95% of the intervals would contain the true population parameter.\n",
    "\n",
    "The formula for a confidence interval for a population mean is:\n",
    "\n",
    "\\[\n",
    "\\bar{x} \\pm Z_{\\alpha/2} \\frac{\\sigma}{\\sqrt{n}}\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( \\bar{x} \\) is the sample mean,\n",
    "- \\( Z_{\\alpha/2} \\) is the critical value from the standard normal distribution,\n",
    "- \\( \\sigma \\) is the population standard deviation,\n",
    "- \\( n \\) is the sample size.\n",
    "\n",
    "---\n",
    "\n",
    "## **9. Random Variables**\n",
    "### **Q9: What is a random variable?**\n",
    "\n",
    "**Answer:**\n",
    "A **random variable** is a variable whose value is subject to randomness. It can take different values based on the outcome of a random event. There are two types of random variables:\n",
    "1. **Discrete random variables**: Take a finite number of distinct values (e.g., number of heads in 10 coin flips).\n",
    "2. **Continuous random variables**: Can take any value within a given range (e.g., height, weight).\n",
    "\n",
    "In machine learning, random variables are often used to model uncertainty, such as in **Bayesian Inference** or **Markov Chains**.\n",
    "\n",
    "---\n",
    "\n",
    "## **10. Law of Large Numbers**\n",
    "### **Q10: What is the Law of Large Numbers?**\n",
    "\n",
    "**Answer:**\n",
    "The **Law of Large Numbers** states that as the sample size increases, the sample mean will get closer to the population mean. This is fundamental in statistics because it ensures that with a large enough sample size, we can estimate population parameters with a high degree of accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "## **11. Correlation and Covariance**\n",
    "### **Q11: What is the difference between covariance and correlation?**\n",
    "\n",
    "**Answer:**\n",
    "- **Covariance** measures the degree to which two variables change together. If both variables increase together, the covariance is positive, while if one increases as the other decreases, it is negative.\n",
    "  \\[\n",
    "  \\text{Cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})\n",
    "  \\]\n",
    "\n",
    "- **Correlation** is a normalized measure of the strength and direction of the relationship between two variables, bounded between -1 and 1. It is computed by dividing the covariance by the product of the standard deviations of the two variables:\n",
    "  \\[\n",
    "  \\text{Corr}(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\sigma_X \\sigma_Y}\n",
    "  \\]\n",
    "\n",
    "Correlation gives a more interpretable measure of the linear relationship between two variables.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## **12. Random Processes**\n",
    "### **Q1: What is a random process?**\n",
    "\n",
    "**Answer:**\n",
    "A **random process** (or stochastic process) is a collection of random variables indexed by time or space. It represents a sequence of random events that evolve over time, such as the daily temperature or stock prices.\n",
    "\n",
    "For example, a **Markov process** is a random process where the future state depends only on the current state and not on past states.\n",
    "\n",
    "---\n",
    "\n",
    "## **13. Expectation and Variance**\n",
    "### **Q2: What is the expectation of a random variable?**\n",
    "\n",
    "**Answer:**\n",
    "The **expectation** (or **expected value**) of a random variable \\( X \\), denoted as \\( E(X) \\), is the long-run average or mean value of \\( X \\) if the experiment were repeated many times. For a discrete random variable:\n",
    "\n",
    "\\[\n",
    "E(X) = \\sum_{i} x_i P(x_i)\n",
    "\\]\n",
    "\n",
    "For a continuous random variable:\n",
    "\n",
    "\\[\n",
    "E(X) = \\int_{-\\infty}^{\\infty} x f(x) \\, dx\n",
    "\\]\n",
    "\n",
    "where \\( f(x) \\) is the probability density function (PDF) of \\( X \\).\n",
    "\n",
    "---\n",
    "\n",
    "## **14. Covariance and Correlation**\n",
    "### **Q3: How do you interpret covariance and correlation between two variables?**\n",
    "\n",
    "**Answer:**\n",
    "- **Covariance** tells us the direction of the linear relationship between two variables. A positive covariance indicates that as one variable increases, the other tends to increase, and vice versa for negative covariance. However, covariance doesn't indicate the strength of the relationship.\n",
    "  \n",
    "- **Correlation** standardizes the covariance to produce a value between -1 and 1, making it easier to interpret:\n",
    "  - A correlation of 1 means a perfect positive linear relationship.\n",
    "  - A correlation of -1 means a perfect negative linear relationship.\n",
    "  - A correlation of 0 means no linear relationship.\n",
    "\n",
    "---\n",
    "\n",
    "## **15. Probability Distributions**\n",
    "### **Q4: What are the differences between discrete and continuous probability distributions?**\n",
    "\n",
    "**Answer:**\n",
    "- **Discrete probability distributions** describe the probability of outcomes for discrete random variables (e.g., rolling a die). Examples include:\n",
    "  - **Binomial distribution**\n",
    "  - **Poisson distribution**\n",
    "  \n",
    "- **Continuous probability distributions** describe the probability of outcomes for continuous random variables (e.g., heights of individuals). Examples include:\n",
    "  - **Normal distribution**\n",
    "  - **Exponential distribution**\n",
    "  \n",
    "In continuous distributions, the probability of any specific value is zero, and probabilities are expressed over intervals.\n",
    "\n",
    "---\n",
    "\n",
    "## **16. Central Limit Theorem**\n",
    "### **Q5: How does the Central Limit Theorem (CLT) apply to sampling?**\n",
    "\n",
    "**Answer:**\n",
    "The **Central Limit Theorem** (CLT) states that the distribution of the sample mean of a large number of independent, identically distributed random variables will be approximately normal, regardless of the original distribution of the data. This is true even if the original data is not normally distributed, as long as the sample size is sufficiently large.\n",
    "\n",
    "The CLT allows us to make inferences about population means based on sample statistics, a cornerstone of statistical hypothesis testing.\n",
    "\n",
    "---\n",
    "\n",
    "## **17. Confidence Intervals**\n",
    "### **Q6: What is the formula for a confidence interval for a population proportion?**\n",
    "\n",
    "**Answer:**\n",
    "The **confidence interval** for a population proportion \\( p \\) is given by:\n",
    "\n",
    "\\[\n",
    "\\hat{p} \\pm Z_{\\alpha/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( \\hat{p} \\) is the sample proportion,\n",
    "- \\( Z_{\\alpha/2} \\) is the critical value from the standard normal distribution (e.g., for a 95% confidence level, \\( Z_{\\alpha/2} = 1.96 \\)),\n",
    "- \\( n \\) is the sample size.\n",
    "\n",
    "This interval estimates the range in which the true population proportion is likely to fall.\n",
    "\n",
    "---\n",
    "\n",
    "## **18. Sampling Methods**\n",
    "### **Q7: What is the difference between random sampling and stratified sampling?**\n",
    "\n",
    "**Answer:**\n",
    "- **Random Sampling**: Every member of the population has an equal chance of being selected. This method ensures each data point has an equal probability of selection, but it may not represent subgroups well.\n",
    "  \n",
    "- **Stratified Sampling**: The population is divided into distinct subgroups (strata), and random samples are taken from each subgroup. This ensures that each subgroup is properly represented in the sample, which can improve the accuracy of estimates for heterogeneous populations.\n",
    "\n",
    "---\n",
    "\n",
    "## **19. Bayes' Theorem in Practice**\n",
    "### **Q8: How do you apply Bayes' Theorem to a diagnostic test problem?**\n",
    "\n",
    "**Answer:**\n",
    "In the context of a diagnostic test, Bayes' Theorem allows us to calculate the probability of a patient having a disease given a positive test result. The formula is:\n",
    "\n",
    "\\[\n",
    "P(\\text{Disease}|\\text{Positive Test}) = \\frac{P(\\text{Positive Test}|\\text{Disease}) P(\\text{Disease})}{P(\\text{Positive Test})}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( P(\\text{Disease}|\\text{Positive Test}) \\) is the posterior probability of having the disease given a positive test result.\n",
    "- \\( P(\\text{Positive Test}|\\text{Disease}) \\) is the likelihood of a positive test given the disease (sensitivity).\n",
    "- \\( P(\\text{Disease}) \\) is the prior probability of having the disease.\n",
    "- \\( P(\\text{Positive Test}) \\) is the total probability of a positive test.\n",
    "\n",
    "---\n",
    "\n",
    "## **20. Markov Chains**\n",
    "### **Q9: What is a Markov Chain and how is it used in machine learning?**\n",
    "\n",
    "**Answer:**\n",
    "A **Markov Chain** is a type of random process where the future state depends only on the current state and not on the sequence of events that preceded it. It is defined by a **transition matrix** that provides the probabilities of moving from one state to another.\n",
    "\n",
    "Markov Chains are used in:\n",
    "- **Hidden Markov Models (HMMs)** for time series and sequential data analysis.\n",
    "- **Reinforcement learning**, where the agentâ€™s next state depends only on the current state and action.\n",
    "\n",
    "---\n",
    "\n",
    "## **21. The Poisson Distribution**\n",
    "### **Q10: What is the Poisson distribution, and when is it used?**\n",
    "\n",
    "**Answer:**\n",
    "The **Poisson distribution** is a discrete probability distribution that models the number of events occurring in a fixed interval of time or space, given that the events occur independently and at a constant rate. The probability mass function is:\n",
    "\n",
    "\\[\n",
    "P(X = k) = \\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( \\lambda \\) is the average number of events in the interval,\n",
    "- \\( k \\) is the number of events,\n",
    "- \\( e \\) is Euler's number.\n",
    "\n",
    "The Poisson distribution is used in machine learning for modeling rare events, such as system failures or the number of customer arrivals at a service center.\n",
    "\n",
    "---\n",
    "\n",
    "## **22. Likelihood Function**\n",
    "### **Q11: What is the likelihood function in statistical modeling?**\n",
    "\n",
    "**Answer:**\n",
    "The **likelihood function** represents the probability of observing the data given a set of model parameters. In other words, it is the probability of the data under different parameter values.\n",
    "\n",
    "For a set of observations \\( x_1, x_2, ..., x_n \\), the likelihood function is:\n",
    "\n",
    "\\[\n",
    "L(\\theta) = P(X = x_1, x_2, ..., x_n | \\theta)\n",
    "\\]\n",
    "\n",
    "In machine learning, we often maximize the likelihood function (Maximum Likelihood Estimation, MLE) to estimate the model parameters that make the observed data most probable.\n",
    "\n",
    "---\n",
    "\n",
    "## **23. The Chi-Squared Test**\n",
    "### **Q12: What is the Chi-Squared test, and how is it used?**\n",
    "\n",
    "**Answer:**\n",
    "The **Chi-Squared test** is a statistical test used to determine if there is a significant association between two categorical variables. It compares the observed frequencies of categories with the expected frequencies under the assumption of no association.\n",
    "\n",
    "The test statistic is given by:\n",
    "\n",
    "\\[\n",
    "\\chi^2 = \\sum \\frac{(O_i - E_i)^2}{E_i}\n",
    "\\]\n",
    "\n",
    "where \\( O_i \\) is the observed frequency and \\( E_i \\) is the expected frequency.\n",
    "\n",
    "In machine learning, the Chi-Squared test is used for feature selection in classification problems.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## **24. Probability Density Function (PDF)**\n",
    "### **Q1: What is a probability density function (PDF) and how is it used?**\n",
    "\n",
    "**Answer:**\n",
    "A **probability density function (PDF)** is a function that describes the likelihood of a continuous random variable taking on a particular value. The area under the curve of the PDF over a given interval represents the probability that the random variable falls within that interval.\n",
    "\n",
    "For a continuous random variable \\( X \\), the PDF is denoted as \\( f(x) \\), and the probability that \\( X \\) lies within a range \\( [a, b] \\) is:\n",
    "\n",
    "\\[\n",
    "P(a \\leq X \\leq b) = \\int_a^b f(x) \\, dx\n",
    "\\]\n",
    "\n",
    "The total area under the curve of the PDF equals 1, i.e.,\n",
    "\n",
    "\\[\n",
    "\\int_{-\\infty}^{\\infty} f(x) \\, dx = 1\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "## **25. Bernoulli Distribution**\n",
    "### **Q2: What is the Bernoulli distribution and when is it used?**\n",
    "\n",
    "**Answer:**\n",
    "The **Bernoulli distribution** models a random experiment with exactly two possible outcomes: success or failure. It is used when there is a binary outcome, such as flipping a coin (heads or tails), passing or failing a test, etc.\n",
    "\n",
    "The probability mass function for a Bernoulli random variable \\( X \\) is:\n",
    "\n",
    "\\[\n",
    "P(X = x) = p^x (1 - p)^{1-x}\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( p \\) is the probability of success (e.g., the probability of heads in a coin flip),\n",
    "- \\( x \\in \\{0, 1\\} \\) represents failure (0) or success (1).\n",
    "\n",
    "---\n",
    "\n",
    "## **26. Bayes' Theorem for Classification**\n",
    "### **Q3: How is Bayes' Theorem applied to classification problems?**\n",
    "\n",
    "**Answer:**\n",
    "Bayes' Theorem is a powerful tool for updating the probability of a hypothesis based on new evidence. In classification, Bayes' Theorem is used to compute the posterior probability of a class given the data (features).\n",
    "\n",
    "For class \\( C \\) and data \\( X \\), Bayes' Theorem states:\n",
    "\n",
    "\\[\n",
    "P(C|X) = \\frac{P(X|C) P(C)}{P(X)}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( P(C|X) \\) is the posterior probability of class \\( C \\) given the data \\( X \\),\n",
    "- \\( P(X|C) \\) is the likelihood, the probability of observing \\( X \\) given class \\( C \\),\n",
    "- \\( P(C) \\) is the prior probability of class \\( C \\),\n",
    "- \\( P(X) \\) is the evidence or marginal likelihood of \\( X \\).\n",
    "\n",
    "In machine learning, this is fundamental to **Naive Bayes classifiers**, where the assumption is that features are conditionally independent given the class.\n",
    "\n",
    "---\n",
    "\n",
    "## **27. Conditional Probability**\n",
    "### **Q4: What is conditional probability and how is it calculated?**\n",
    "\n",
    "**Answer:**\n",
    "**Conditional probability** is the probability of an event occurring given that another event has already occurred. The conditional probability of event \\( A \\) given event \\( B \\) is denoted as \\( P(A|B) \\), and it is calculated using the formula:\n",
    "\n",
    "\\[\n",
    "P(A|B) = \\frac{P(A \\cap B)}{P(B)}\n",
    "\\]\n",
    "\n",
    "Where:\n",
    "- \\( P(A \\cap B) \\) is the probability of both events \\( A \\) and \\( B \\) occurring,\n",
    "- \\( P(B) \\) is the probability of event \\( B \\).\n",
    "\n",
    "In machine learning, conditional probability is used for tasks such as predicting the likelihood of an outcome given certain features.\n",
    "\n",
    "---\n",
    "\n",
    "## **28. Law of Total Probability**\n",
    "### **Q5: What is the law of total probability and how is it used?**\n",
    "\n",
    "**Answer:**\n",
    "The **law of total probability** states that the total probability of an event can be found by considering all possible conditions or partitions of the sample space. It is expressed as:\n",
    "\n",
    "\\[\n",
    "P(A) = \\sum_{i} P(A|B_i) P(B_i)\n",
    "\\]\n",
    "\n",
    "where \\( B_i \\) are mutually exclusive events that partition the sample space. This law is useful in Bayesian inference when you have different scenarios or conditions to consider.\n",
    "\n",
    "In machine learning, it is applied when considering different classes or features in probabilistic models.\n",
    "\n",
    "---\n",
    "\n",
    "## **29. The Exponential Distribution**\n",
    "### **Q6: What is the Exponential distribution and what is it used for?**\n",
    "\n",
    "**Answer:**\n",
    "The **Exponential distribution** is a continuous probability distribution used to model the time between events in a Poisson process, where events occur at a constant average rate. Its probability density function is:\n",
    "\n",
    "\\[\n",
    "f(x; \\lambda) = \\lambda e^{-\\lambda x} \\quad \\text{for} \\quad x \\geq 0\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( \\lambda \\) is the rate parameter (the inverse of the mean time between events).\n",
    "\n",
    "The Exponential distribution is commonly used in modeling the time between failures of machines, the time until a customer arrives at a service center, etc.\n",
    "\n",
    "---\n",
    "\n",
    "## **30. The Normal Distribution**\n",
    "### **Q7: What is the Normal distribution, and how is it important in statistics and machine learning?**\n",
    "\n",
    "**Answer:**\n",
    "The **Normal distribution** (also called Gaussian distribution) is a continuous probability distribution characterized by its bell-shaped curve. It is defined by two parameters: the mean \\( \\mu \\) and the standard deviation \\( \\sigma \\). The probability density function is:\n",
    "\n",
    "\\[\n",
    "f(x; \\mu, \\sigma) = \\frac{1}{\\sigma \\sqrt{2\\pi}} e^{-\\frac{(x - \\mu)^2}{2\\sigma^2}}\n",
    "\\]\n",
    "\n",
    "The Normal distribution is important in statistics and machine learning because:\n",
    "- Many real-world phenomena (e.g., height, test scores, measurement errors) follow a Normal distribution.\n",
    "- The **Central Limit Theorem** states that the sum of a large number of independent random variables will follow a Normal distribution.\n",
    "- In machine learning, many algorithms (e.g., Naive Bayes, linear regression) assume data is normally distributed for simplification.\n",
    "\n",
    "---\n",
    "\n",
    "## **31. The t-Distribution**\n",
    "### **Q8: What is the t-distribution, and when is it used?**\n",
    "\n",
    "**Answer:**\n",
    "The **t-distribution** is a family of probability distributions that are similar to the normal distribution but have heavier tails. It is used primarily in hypothesis testing, particularly when the sample size is small and the population standard deviation is unknown. The probability density function is:\n",
    "\n",
    "\\[\n",
    "f(x; \\nu) = \\frac{\\Gamma\\left(\\frac{\\nu + 1}{2}\\right)}{\\sqrt{\\nu \\pi} \\Gamma\\left(\\frac{\\nu}{2}\\right)} \\left( 1 + \\frac{x^2}{\\nu} \\right)^{-\\frac{\\nu + 1}{2}}\n",
    "\\]\n",
    "\n",
    "where \\( \\nu \\) is the degrees of freedom.\n",
    "\n",
    "The t-distribution is used in **t-tests** for comparing sample means, especially when working with small sample sizes.\n",
    "\n",
    "---\n",
    "\n",
    "## **32. Bootstrapping**\n",
    "### **Q9: What is bootstrapping in statistics and how is it applied?**\n",
    "\n",
    "**Answer:**\n",
    "**Bootstrapping** is a resampling technique used to estimate the distribution of a statistic by repeatedly sampling with replacement from the observed data. This allows estimation of standard errors, confidence intervals, and other properties without assuming a specific distribution.\n",
    "\n",
    "For example, to estimate the mean and its confidence interval using bootstrapping:\n",
    "1. Resample the original data with replacement to create a new sample.\n",
    "2. Compute the statistic (e.g., the mean) for the resampled data.\n",
    "3. Repeat this process many times (e.g., 1000 times) to create a distribution of the statistic.\n",
    "\n",
    "Bootstrapping is often used in machine learning to estimate the uncertainty of model parameters and in algorithms like **Random Forests**.\n",
    "\n",
    "---\n",
    "\n",
    "## **33. The Gamma Distribution**\n",
    "### **Q10: What is the Gamma distribution and what is it used for?**\n",
    "\n",
    "**Answer:**\n",
    "The **Gamma distribution** is a two-parameter continuous probability distribution that generalizes the Exponential distribution. It is commonly used to model waiting times or lifetimes of processes with multiple stages.\n",
    "\n",
    "The probability density function is:\n",
    "\n",
    "\\[\n",
    "f(x; \\alpha, \\beta) = \\frac{x^{\\alpha - 1} e^{-x / \\beta}}{\\beta^\\alpha \\Gamma(\\alpha)}\n",
    "\\]\n",
    "\n",
    "where:\n",
    "- \\( \\alpha \\) is the shape parameter,\n",
    "- \\( \\beta \\) is the scale parameter,\n",
    "- \\( \\Gamma(\\alpha) \\) is the Gamma function.\n",
    "\n",
    "In machine learning, the Gamma distribution is used in survival analysis, queuing theory, and modeling of variables that are always positive and have a skewed distribution.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
