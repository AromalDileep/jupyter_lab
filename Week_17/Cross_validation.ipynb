{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6764ccc6-e377-4cee-9612-8f3789428555",
   "metadata": {},
   "source": [
    "### 1. **Leave-One-Out Cross-Validation (LOOCV)**\n",
    "#### Description:\n",
    "- LOOCV is a special case of $k$-fold CV where $k = n$ (number of samples).\n",
    "- Each data point is used once as the validation set, while the rest $n-1$ are used for training.\n",
    "\n",
    "#### How It Works:\n",
    "1. Divide the dataset into $n$ folds, where each fold contains a single sample.\n",
    "2. Train the model on $n-1$ samples and validate on the remaining 1 sample.\n",
    "3. Repeat for all $n$ samples.\n",
    "4. Calculate the average metric (e.g., accuracy, MSE) across all iterations.\n",
    "\n",
    "#### Example:\n",
    "- Dataset: 5 samples $[A, B, C, D, E]$\n",
    "- Iterations:\n",
    "  1. Train on $[B, C, D, E]$, test on $[A]$.\n",
    "  2. Train on $[A, C, D, E]$, test on $[B]$.\n",
    "  3. Repeat for the remaining samples.\n",
    "\n",
    "#### Use Case:\n",
    "- **Small datasets**: E.g., medical datasets with only 100 patients.\n",
    "- Helps evaluate models when maximizing the training set size is crucial.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Leave-P-Out Cross-Validation**\n",
    "#### Description:\n",
    "- Generalization of LOOCV where $p$ samples are left out for validation.\n",
    "- Tests all possible combinations of $p$-sized subsets.\n",
    "\n",
    "#### How It Works:\n",
    "1. Generate all combinations of $p$ samples from the dataset.\n",
    "2. For each subset of $p$:\n",
    "   - Train on the remaining $n-p$ samples.\n",
    "   - Test on the $p$ samples.\n",
    "3. Average the performance metrics across all combinations.\n",
    "\n",
    "#### Example:\n",
    "- Dataset: 4 samples $[A, B, C, D]$, $p = 2$.\n",
    "- Combinations of $p = 2$: $(A, B), (A, C), (A, D), (B, C), (B, D), (C, D)$.\n",
    "- Iterations:\n",
    "  1. Train on $[C, D]$, test on $[A, B]$.\n",
    "  2. Train on $[B, D]$, test on $[A, C]$.\n",
    "  3. Continue for all combinations.\n",
    "\n",
    "#### Use Case:\n",
    "- Rarely used due to high computational cost.\n",
    "- Can be useful for **exhaustive testing** in **very small datasets**.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **K-Fold Cross-Validation**\n",
    "#### Description:\n",
    "- The dataset is split into $k$ approximately equal-sized folds.\n",
    "- Each fold is used as a validation set once, while the remaining $k-1$ folds are used for training.\n",
    "\n",
    "#### How It Works:\n",
    "1. Shuffle the data randomly (optional).\n",
    "2. Split the data into $k$ folds.\n",
    "3. For each fold:\n",
    "   - Train on $k-1$ folds.\n",
    "   - Test on the remaining fold.\n",
    "4. Average the performance metrics across all folds.\n",
    "\n",
    "#### Example:\n",
    "- Dataset: 10 samples.\n",
    "- $k = 5$ (5-fold CV).\n",
    "- Iterations:\n",
    "  1. Train on folds $[2, 3, 4, 5]$, test on fold $1$.\n",
    "  2. Train on folds $[1, 3, 4, 5]$, test on fold $2$.\n",
    "  3. Continue for all folds.\n",
    "\n",
    "#### Use Case:\n",
    "- **Default choice** for most supervised learning tasks.\n",
    "- Use $k = 5$ or $k = 10$ for balance between computation and evaluation.\n",
    "\n",
    "#### Example Case:\n",
    "- Predicting house prices using features like area, bedrooms, and location.\n",
    "- Use $k$-fold CV to evaluate model performance on unseen data.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Stratified K-Fold Cross-Validation**\n",
    "#### Description:\n",
    "- A variation of $k$-fold CV where folds are created to preserve the same class distribution as in the original dataset.\n",
    "- Ensures balance in classification tasks with imbalanced datasets.\n",
    "\n",
    "#### How It Works:\n",
    "1. Divide the dataset into $k$ folds, maintaining the proportion of each class in every fold.\n",
    "2. Follow the same process as $k$-fold CV.\n",
    "\n",
    "#### Example:\n",
    "- Dataset: 100 samples (80 Class A, 20 Class B).\n",
    "- $k = 5$ (Stratified 5-fold CV).\n",
    "- Each fold contains 16 Class A samples and 4 Class B samples.\n",
    "\n",
    "#### Use Case:\n",
    "- **Imbalanced classification problems**: E.g., fraud detection, cancer diagnosis, or sentiment analysis.\n",
    "- Prevents bias caused by under-represented classes.\n",
    "\n",
    "#### Example Case:\n",
    "- Predicting whether a credit card transaction is fraudulent (1% fraudulent, 99% non-fraudulent).\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Time Series Cross-Validation**\n",
    "#### Description:\n",
    "- Designed for **time-dependent data** where maintaining temporal order is critical.\n",
    "- Ensures training data includes only observations that occurred before the validation set.\n",
    "\n",
    "#### How It Works:\n",
    "Two main approaches:\n",
    "1. **Rolling Window:**\n",
    "   - Use a fixed-size training window that \"rolls forward.\"\n",
    "   - Train on earlier data, validate on subsequent data.\n",
    "\n",
    "2. **Expanding Window:**\n",
    "   - Start with a small training set and expand it over time.\n",
    "   - Train on all data up to a certain point, validate on the next segment.\n",
    "\n",
    "#### Example (Expanding Window):\n",
    "- Dataset: Time series data from January to December.\n",
    "- Train/Validation Splits:\n",
    "  1. Train: January-February, Validate: March.\n",
    "  2. Train: January-March, Validate: April.\n",
    "  3. Continue until December.\n",
    "\n",
    "#### Use Case:\n",
    "- Time series forecasting: E.g., stock prices, weather predictions, sales forecasting.\n",
    "\n",
    "---\n",
    "\n",
    "### Comparison Table:\n",
    "\n",
    "| **CV Type**              | **Description**                                  | **Example Case**                                           | **When to Use**                                   |\n",
    "|---------------------------|------------------------------------------------|-----------------------------------------------------------|--------------------------------------------------|\n",
    "| **LOOCV**                | Leave one point for validation, train on $n-1$. | Small dataset of 50 patients for medical predictions.      | Small datasets or avoiding overfitting.          |\n",
    "| **Leave-P-Out**           | Leave $p$ points for validation.               | Dataset with 10 samples; exhaustive testing for robustness. | Rarely used; computationally expensive.          |\n",
    "| **K-Fold CV**             | Divide into $k$ folds; use one fold for validation. | House price prediction with $k = 5$.                      | General-purpose CV for most tasks.              |\n",
    "| **Stratified K-Fold CV**  | Like $k$-fold but preserves class distribution. | Fraud detection (1% fraud cases).                         | Classification with imbalanced datasets.        |\n",
    "| **Time Series CV**        | Respects temporal order; uses rolling/expanding windows. | Predicting stock prices using past data.                  | Sequential or time-dependent data.              |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adb473c-da9b-49c0-8aac-d68e29070500",
   "metadata": {},
   "source": [
    "## Difference of Leave-p-out CV and K-fold CV\n",
    "---\n",
    "\n",
    "### **1. Leave-p-out Cross-Validation (LPOCV):**\n",
    "- **Description**: In LPOCV, **p data points** are left out of the dataset as the validation set, while the remaining data points are used for training. This process is repeated for all possible combinations of \\( p \\) points from the dataset.\n",
    "- **Number of Splits**: The number of splits is $ \\binom{n}{p} $, where \\( n \\) is the total number of data points in the dataset. This makes LPOCV computationally expensive for large datasets.\n",
    "- **Granularity**: Very fine-grained as it explores multiple combinations of subsets.\n",
    "- **Use Case**: Suitable for small datasets where it is feasible to evaluate all possible combinations.\n",
    "- **Pros**:\n",
    "  - Provides a more exhaustive evaluation since it considers all possible ways of splitting the data.\n",
    "- **Cons**:\n",
    "  - Computationally expensive and impractical for large datasets.\n",
    "  - May lead to overfitting in small datasets because the model is evaluated on a very small subset.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. K-fold Cross-Validation (KFCV):**\n",
    "- **Description**: The dataset is divided into \\( k \\) equally (or almost equally) sized folds. In each iteration, one fold is used as the validation set, and the remaining \\( k-1 \\) folds are used for training. This process is repeated \\( k \\) times, ensuring each fold is used as a validation set once.\n",
    "- **Number of Splits**: Exactly \\( k \\), where \\( k \\) is a user-defined parameter (typically 5 or 10).\n",
    "- **Granularity**: Coarser than LPOCV but balances efficiency and performance evaluation.\n",
    "- **Use Case**: The standard approach for larger datasets or when computational resources are limited.\n",
    "- **Pros**:\n",
    "  - Computationally efficient compared to LPOCV.\n",
    "  - Provides a good balance between bias and variance in the performance estimate.\n",
    "- **Cons**:\n",
    "  - Less exhaustive compared to LPOCV.\n",
    "  - The choice of \\( k \\) can influence the results.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Differences:**\n",
    "\n",
    "| Feature                        | Leave-p-out Cross-Validation (LPOCV)               | K-fold Cross-Validation (KFCV)                  |\n",
    "|--------------------------------|----------------------------------------------------|------------------------------------------------|\n",
    "| **Split Method**               | All combinations of \\( p \\) points as validation. | Divides data into \\( k \\) equal-sized folds.   |\n",
    "| **Number of Splits**           | $ \\binom{n}{p}$ (combinatorial explosion).      | \\( k \\) splits (manageable).                  |\n",
    "| **Computational Efficiency**   | Very expensive, grows combinatorially.            | Efficient, linear with \\( k \\).               |\n",
    "| **Use Case**                   | Small datasets, exhaustive evaluation.            | Large datasets, practical evaluation.         |\n",
    "| **Granularity**                | More granular.                                     | Coarser.                                      |\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use Which?**\n",
    "1. **LPOCV**:\n",
    "   - Best for **small datasets** where computational cost is manageable.\n",
    "   - Useful when you need exhaustive testing of all possible splits.\n",
    "\n",
    "2. **KFCV**:\n",
    "   - Standard choice for **larger datasets** and when computational efficiency is required.\n",
    "   - Balances the trade-off between exhaustive evaluation and practicality.\n",
    "\n",
    "If you are working on large datasets or resource-constrained environments, **K-fold cross-validation** is the preferred option. However, for very small datasets where model performance is highly sensitive to the data split, **LPOCV** might be a better fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56742306-c8c6-477a-b485-52028e4bae16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
