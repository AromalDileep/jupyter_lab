{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f5b26d6-8ebe-464d-a783-d8c7f303161b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **1. Mean Squared Error (MSE)**:\n",
    "- **Definition**: MSE measures the average squared difference between the predicted values (\\(\\hat{y}\\)) and the actual values (\\(y\\)) in a dataset.\n",
    "- **Formula**:  \n",
    "    $\n",
    "  \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2\n",
    "  $\n",
    "  \n",
    "  where:\n",
    "  - $(n)$ is the number of observations,\n",
    "  - $(y_i)$ is the actual value,\n",
    "  - $(\\hat{y}_i)$ is the predicted value.\n",
    "\n",
    "- **Purpose**: It is a measure of the **error** or **loss** in predictions, often used in regression models to evaluate their performance. A smaller MSE indicates better predictions.\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Variance**:\n",
    "- **Definition**: Variance measures the average squared deviation of the actual data points $(y)$ from their mean $(\\bar{y})$.\n",
    "- **Formula**:\n",
    "    $\n",
    "  \\text{Variance} = \\frac{1}{n} \\sum_{i=1}^n (y_i - \\bar{y})^2\n",
    "  $\n",
    "  \n",
    "  where:\n",
    "  - $(\\bar{y})$ is the mean of the data.\n",
    "\n",
    "- **Purpose**: It quantifies the **spread** or **dispersion** of the data around the mean, indicating how much the data varies.\n",
    "\n",
    "---\n",
    "\n",
    "### **Key Differences**:\n",
    "| Aspect               | Mean Squared Error (MSE)                          | Variance                                 |\n",
    "|----------------------|---------------------------------------------------|------------------------------------------|\n",
    "| **What it measures** | Error between predicted and actual values         | Spread of actual values around the mean |\n",
    "| **Reference point**  | Predictions (\\(\\hat{y}_i\\))                      | Mean of the data (\\(\\bar{y}\\))          |\n",
    "| **Purpose**          | Evaluate model performance                       | Describe the data distribution          |\n",
    "\n",
    "---\n",
    "\n",
    "### **Relationship**:\n",
    "In regression problems, the **MSE** can be decomposed into **variance**, **bias**, and **irreducible error** (as part of the bias-variance tradeoff):\n",
    "\n",
    "$\n",
    "\\text{MSE} = \\text{Variance} + (\\text{Bias})^2 + \\text{Irreducible Error}\n",
    "$\n",
    "\n",
    "This decomposition shows that while variance is a component of MSE, it is not the same as MSE.\n",
    "\n",
    "---\n",
    "\n",
    "### **Conclusion**:\n",
    "- MSE is a measure of how well a model predicts the actual values.\n",
    "- Variance is a property of the actual data, independent of any model.\n",
    "- They are **not the same** but are related, particularly in the context of regression and error analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93d8848-e2f3-41dc-9b14-9cc1683d6fd1",
   "metadata": {},
   "source": [
    "# Variance reduction\n",
    "\n",
    "$\n",
    "\\text{Variance Reduction} = \\text{Variance (Parent)} - \\sum_{i=1}^k w_i \\cdot \\text{Variance (Child}_i\\text{)}\n",
    "$\n",
    "\n",
    "The formula is used to measure **variance reduction** in decision tree algorithms when splitting a node.\n",
    "\n",
    "---\n",
    "\n",
    "### **Explanation:**\n",
    "\n",
    "1. **Variance (Parent/Root)**:\n",
    "   - This represents the variance of the target variable $(y)$ at the parent node (before the split).\n",
    "\n",
    "2. **Variance (Child)**:\n",
    "   - After a split, the target values are divided into $(k)$ child nodes (e.g., for binary splits, $(k = 2))$.\n",
    "   - Each child node has its own variance.\n",
    "\n",
    "3. **Weights $(w_i)$**:\n",
    "   - The weights $(w_i)$ represent the proportion of data points in each child node relative to the total data points in the parent node:\n",
    "     $\n",
    "     w_i = \\frac{\\text{Number of data points in Child}_i}{\\text{Total number of data points in Parent}}\n",
    "     $\n",
    "\n",
    "4. **Summation**:\n",
    "   - The weighted sum of the variances of the child nodes represents the combined variance after the split.\n",
    "\n",
    "5. **Variance Reduction**:\n",
    "   - The difference between the parent node's variance and the weighted sum of the child nodes' variances gives the **variance reduction**.\n",
    "   - A larger variance reduction indicates a better split.\n",
    "\n",
    "---\n",
    "\n",
    "### **Use in Decision Trees:**\n",
    "\n",
    "This formula is used to evaluate the quality of a split in regression trees (e.g., **CART for regression**). The algorithm chooses the split that maximizes the variance reduction, aiming to minimize the variance within the child nodes and, consequently, improve the predictive performance of the tree.\n",
    "\n",
    "---\n",
    "\n",
    "### **Formula Recap**:\n",
    "\n",
    "$\n",
    "\\text{Variance Reduction} = \\text{Variance (Parent)} - \\sum_{i=1}^k w_i \\cdot \\text{Variance (Child}_i\\text{)}\n",
    "$\n",
    "\n",
    "Where:\n",
    "- $(\\text{Variance (Parent)} = \\frac{1}{n} \\sum_{j=1}^n (y_j - \\bar{y})^2)$,\n",
    "- $(\\text{Variance (Child}_i\\text{)})$ is calculated similarly for each child node.\n",
    "\n",
    "This formula is commonly applied in regression decision trees."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
